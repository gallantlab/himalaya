
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>Model descriptions &#8212; Himalaya 0.3.6 documentation</title>
    <link rel="stylesheet" type="text/css" href="_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="_static/alabaster.css" />
    <link rel="stylesheet" type="text/css" href="_static/sg_gallery.css" />
    <link rel="stylesheet" type="text/css" href="_static/sg_gallery-binder.css" />
    <link rel="stylesheet" type="text/css" href="_static/sg_gallery-dataframe.css" />
    <link rel="stylesheet" type="text/css" href="_static/sg_gallery-rendered-html.css" />
    <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/doctools.js"></script>
    <script async="async" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script src="https://unpkg.com/mermaid/dist/mermaid.min.js"></script>
    <script>mermaid.initialize({startOnLoad:true});</script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Model flowchart" href="flowchart.html" />
    <link rel="prev" title="Getting started" href="getting_started.html" />
   
  <link rel="stylesheet" href="_static/custom.css" type="text/css" />
  
  
  <meta name="viewport" content="width=device-width, initial-scale=0.9, maximum-scale=0.9" />

  </head><body>
  <div class="document">
    
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
<p class="logo">
  <a href="index.html">
    <img class="logo" src="_static/logo.svg" alt="Logo"/>
    
  </a>
</p>






<p>
<iframe src="https://ghbtns.com/github-btn.html?user=gallantlab&repo=himalaya&type=star&count=true&size=large&v=2"
  allowtransparency="true" frameborder="0" scrolling="0" width="200px" height="35px"></iframe>
</p>





<div class="relations">
<h3>Related Topics</h3>
<ul>
  <li><a href="index.html">Documentation overview</a><ul>
      <li>Previous: <a href="getting_started.html" title="previous chapter">Getting started</a></li>
      <li>Next: <a href="flowchart.html" title="next chapter">Model flowchart</a></li>
  </ul></li>
</ul>
</div><h3>Navigation</h3>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="getting_started.html">Getting started</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Model descriptions</a></li>
<li class="toctree-l1"><a class="reference internal" href="flowchart.html">Model flowchart</a></li>
<li class="toctree-l1"><a class="reference internal" href="troubleshooting.html">Troubleshooting</a></li>
<li class="toctree-l1"><a class="reference internal" href="_auto_examples/index.html">Gallery of examples</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="api.html">API</a></li>
<li class="toctree-l1"><a class="reference internal" href="changelog.html">Changelog</a></li>
</ul>


<div id="searchbox" style="display: none" role="search">
  <h3 id="searchlabel">Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="search.html" method="get">
      <input type="text" name="q" aria-labelledby="searchlabel" autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false"/>
      <input type="submit" value="Go" />
    </form>
    </div>
</div>
<script>$('#searchbox').show(0);</script>
        </div>
      </div>
      <div class="documentwrapper">
        <div class="bodywrapper">
          

          <div class="body" role="main">
            
  <section id="model-descriptions">
<h1>Model descriptions<a class="headerlink" href="#model-descriptions" title="Permalink to this headline">¶</a></h1>
<p>This package implements a number of models.</p>
<section id="ridge">
<h2>Ridge<a class="headerlink" href="#ridge" title="Permalink to this headline">¶</a></h2>
<p>Let <span class="math notranslate nohighlight">\(X\in \mathbb{R}^{n\times p}\)</span> be a feature matrix with <span class="math notranslate nohighlight">\(n\)</span>
samples and <span class="math notranslate nohighlight">\(p\)</span> features,  <span class="math notranslate nohighlight">\(y\in \mathbb{R}^n\)</span> a target vector, and
<span class="math notranslate nohighlight">\(\alpha &gt; 0\)</span> a fixed regularization hyperparameter. Ridge regression
<a class="footnote-reference brackets" href="#id4" id="id1">1</a> defines the weight vector <span class="math notranslate nohighlight">\(b^*\in \mathbb{R}^p\)</span> as:</p>
<div class="math notranslate nohighlight">
\[b^* = \arg\min_b \|Xb - y\|_2^2 + \alpha \|b\|_2^2.\]</div>
<p>The equation has a  closed-form solution <span class="math notranslate nohighlight">\(b^* = M y\)</span>, where <span class="math notranslate nohighlight">\(M =
(X^\top X + \alpha I_p)^{-1}X^\top \in  \mathbb{R}^{p \times n}\)</span>.</p>
<div class="admonition-this-model-is-implemented-in admonition">
<p class="admonition-title">This model is implemented in</p>
<ul class="simple">
<li><p><a class="reference internal" href="_generated/himalaya.ridge.Ridge.html#himalaya.ridge.Ridge" title="himalaya.ridge.Ridge"><code class="xref py py-class docutils literal notranslate"><span class="pre">Ridge</span></code></a> (scikit-learn-compatible estimator)</p></li>
<li><p><a class="reference internal" href="_generated/himalaya.ridge.solve_ridge_svd.html#himalaya.ridge.solve_ridge_svd" title="himalaya.ridge.solve_ridge_svd"><code class="xref py py-func docutils literal notranslate"><span class="pre">solve_ridge_svd()</span></code></a> (function)</p></li>
</ul>
</div>
</section>
<section id="kernelridge">
<h2>KernelRidge<a class="headerlink" href="#kernelridge" title="Permalink to this headline">¶</a></h2>
<p>By the Woodbury matrix identity, <span class="math notranslate nohighlight">\(b^*\)</span> can be written as <span class="math notranslate nohighlight">\(b^* =
X^\top(XX^\top + \alpha I_n)^{-1}y\)</span>, or <span class="math notranslate nohighlight">\(b^* = X^\top w^*\)</span> for some
<span class="math notranslate nohighlight">\(w^*\in \mathbb{R}^n\)</span>. Noting the linear kernel <span class="math notranslate nohighlight">\(K = X X^\top \in
\mathbb{R}^{n\times n}\)</span>, this leads to the <em>equivalent</em> formulation:</p>
<div class="math notranslate nohighlight">
\[w^* = \arg\min_w \|Kw - y\|_2^2 + \alpha w^\top Kw.\]</div>
<p>This model can be extended to arbitrary positive semidefinite kernels
<span class="math notranslate nohighlight">\(K\)</span>, leading to the more general kernel ridge regression <a class="footnote-reference brackets" href="#id5" id="id2">2</a>.</p>
<div class="admonition-this-model-is-implemented-in admonition">
<p class="admonition-title">This model is implemented in</p>
<ul class="simple">
<li><p><a class="reference internal" href="_generated/himalaya.kernel_ridge.KernelRidge.html#himalaya.kernel_ridge.KernelRidge" title="himalaya.kernel_ridge.KernelRidge"><code class="xref py py-class docutils literal notranslate"><span class="pre">KernelRidge</span></code></a> (scikit-learn-compatible estimator)</p></li>
<li><p><a class="reference internal" href="_generated/himalaya.kernel_ridge.solve_kernel_ridge_eigenvalues.html#himalaya.kernel_ridge.solve_kernel_ridge_eigenvalues" title="himalaya.kernel_ridge.solve_kernel_ridge_eigenvalues"><code class="xref py py-func docutils literal notranslate"><span class="pre">solve_kernel_ridge_eigenvalues()</span></code></a> (function)</p></li>
<li><p><a class="reference internal" href="_generated/himalaya.kernel_ridge.solve_kernel_ridge_gradient_descent.html#himalaya.kernel_ridge.solve_kernel_ridge_gradient_descent" title="himalaya.kernel_ridge.solve_kernel_ridge_gradient_descent"><code class="xref py py-func docutils literal notranslate"><span class="pre">solve_kernel_ridge_gradient_descent()</span></code></a> (function)</p></li>
<li><p><a class="reference internal" href="_generated/himalaya.kernel_ridge.solve_kernel_ridge_conjugate_gradient.html#himalaya.kernel_ridge.solve_kernel_ridge_conjugate_gradient" title="himalaya.kernel_ridge.solve_kernel_ridge_conjugate_gradient"><code class="xref py py-func docutils literal notranslate"><span class="pre">solve_kernel_ridge_conjugate_gradient()</span></code></a> (function)</p></li>
</ul>
</div>
</section>
<section id="ridgecv-and-kernelridgecv">
<h2>RidgeCV and KernelRidgeCV<a class="headerlink" href="#ridgecv-and-kernelridgecv" title="Permalink to this headline">¶</a></h2>
<p>In practice, because the ridge regression and kernel ridge regression
hyperparameter <span class="math notranslate nohighlight">\(\alpha\)</span> is unknown, it is typically selected through a
grid-search with cross-validation. In cross-validation, we split the data set
into a training set <span class="math notranslate nohighlight">\((X_{train}, y_{train})\)</span> and a validation set
<span class="math notranslate nohighlight">\((X_{val}, y_{val})\)</span>. Then, we train the model on the training set, and
evaluate the generalization performance on the validation set. We perform this
process for multiple hyperparameter candidates <span class="math notranslate nohighlight">\(\alpha\)</span>, typically
defined over a grid of log-spaced values. Finally, we keep the candidate
leading to the best generalization performance, as measured by the validation
loss, averaged over all cross-validation splits.</p>
<div class="admonition-these-models-are-implemented-in admonition">
<p class="admonition-title">These models are implemented in</p>
<ul class="simple">
<li><p><a class="reference internal" href="_generated/himalaya.ridge.RidgeCV.html#himalaya.ridge.RidgeCV" title="himalaya.ridge.RidgeCV"><code class="xref py py-class docutils literal notranslate"><span class="pre">RidgeCV</span></code></a> (scikit-learn-compatible estimator)</p></li>
<li><p><a class="reference internal" href="_generated/himalaya.ridge.solve_ridge_cv_svd.html#himalaya.ridge.solve_ridge_cv_svd" title="himalaya.ridge.solve_ridge_cv_svd"><code class="xref py py-func docutils literal notranslate"><span class="pre">solve_ridge_cv_svd()</span></code></a> (function)</p></li>
<li><p><a class="reference internal" href="_generated/himalaya.kernel_ridge.KernelRidgeCV.html#himalaya.kernel_ridge.KernelRidgeCV" title="himalaya.kernel_ridge.KernelRidgeCV"><code class="xref py py-class docutils literal notranslate"><span class="pre">KernelRidgeCV</span></code></a> (scikit-learn-compatible estimator)</p></li>
<li><p><a class="reference internal" href="_generated/himalaya.kernel_ridge.solve_kernel_ridge_cv_eigenvalues.html#himalaya.kernel_ridge.solve_kernel_ridge_cv_eigenvalues" title="himalaya.kernel_ridge.solve_kernel_ridge_cv_eigenvalues"><code class="xref py py-func docutils literal notranslate"><span class="pre">solve_kernel_ridge_cv_eigenvalues()</span></code></a> (function)</p></li>
</ul>
</div>
</section>
<section id="groupridgecv-bandedridgecv">
<h2>GroupRidgeCV / BandedRidgeCV<a class="headerlink" href="#groupridgecv-bandedridgecv" title="Permalink to this headline">¶</a></h2>
<p>In some applications, features are naturally grouped into groups (or feature
spaces). To adapt the regularization level to each feature space, ridge
regression can be extended to group-regularized ridge regression (also known
as banded ridge regression <a class="footnote-reference brackets" href="#id6" id="id3">3</a>). In this model, a separate hyperparameter is
optimized for each feature space:</p>
<div class="math notranslate nohighlight">
\[b^* = \arg\min_b \|\sum_{i=1}^m X_i b_i - y\|_2^2 + \sum_{i=1}^m \alpha_i \|b_i\|_2^2.\]</div>
<p>This is equivalent to solving a ridge regression:</p>
<div class="math notranslate nohighlight">
\[b^* = \arg\min_b \|Z b - Y\|_2^2 + \|b\|_2^2\]</div>
<p>where the feature space <span class="math notranslate nohighlight">\(X_i\)</span> is scaled by a group scaling <span class="math notranslate nohighlight">\(Z_i =
e^{\delta_i} X_i\)</span>. The hyperparameters <span class="math notranslate nohighlight">\(\delta_i = - \log(\alpha_i)\)</span> are
then learned over cross-validation.</p>
<div class="admonition-this-model-is-implemented-in admonition">
<p class="admonition-title">This model is implemented in</p>
<ul class="simple">
<li><p><a class="reference internal" href="_generated/himalaya.ridge.GroupRidgeCV.html#himalaya.ridge.GroupRidgeCV" title="himalaya.ridge.GroupRidgeCV"><code class="xref py py-class docutils literal notranslate"><span class="pre">GroupRidgeCV</span></code></a> (scikit-learn-compatible estimator)</p></li>
<li><p><a class="reference internal" href="_generated/himalaya.ridge.solve_group_ridge_random_search.html#himalaya.ridge.solve_group_ridge_random_search" title="himalaya.ridge.solve_group_ridge_random_search"><code class="xref py py-func docutils literal notranslate"><span class="pre">solve_group_ridge_random_search()</span></code></a> (function)</p></li>
</ul>
<p>See also multiple-kernel ridge regression, which is equivalent to
group-regularization ridge regression when using one linear kernel per group
of features:</p>
<ul class="simple">
<li><p><a class="reference internal" href="_generated/himalaya.kernel_ridge.MultipleKernelRidgeCV.html#himalaya.kernel_ridge.MultipleKernelRidgeCV" title="himalaya.kernel_ridge.MultipleKernelRidgeCV"><code class="xref py py-class docutils literal notranslate"><span class="pre">MultipleKernelRidgeCV</span></code></a> (scikit-learn-compatible estimator)</p></li>
<li><p><a class="reference internal" href="_generated/himalaya.kernel_ridge.solve_multiple_kernel_ridge_random_search.html#himalaya.kernel_ridge.solve_multiple_kernel_ridge_random_search" title="himalaya.kernel_ridge.solve_multiple_kernel_ridge_random_search"><code class="xref py py-func docutils literal notranslate"><span class="pre">solve_multiple_kernel_ridge_random_search()</span></code></a> (function)</p></li>
<li><p><a class="reference internal" href="_generated/himalaya.kernel_ridge.solve_multiple_kernel_ridge_hyper_gradient.html#himalaya.kernel_ridge.solve_multiple_kernel_ridge_hyper_gradient" title="himalaya.kernel_ridge.solve_multiple_kernel_ridge_hyper_gradient"><code class="xref py py-func docutils literal notranslate"><span class="pre">solve_multiple_kernel_ridge_hyper_gradient()</span></code></a> (function)</p></li>
</ul>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>“Group ridge regression” is also sometimes called “Banded ridge regression”.</p>
</div>
</section>
<section id="weightedkernelridge">
<h2>WeightedKernelRidge<a class="headerlink" href="#weightedkernelridge" title="Permalink to this headline">¶</a></h2>
<p>To extend kernel ridge to group-regularization, we can compute the kernel as a
weighted sum of multiple kernels, <span class="math notranslate nohighlight">\(K = \sum_{i=1}^m e^{\delta_i} K_i\)</span>.
Then, we can use <span class="math notranslate nohighlight">\(K_i = X_i X_i^\top\)</span> for different groups of features
<span class="math notranslate nohighlight">\(X_i\)</span>. The model becomes:</p>
<div class="math notranslate nohighlight">
\[w^* = \arg\min_w \left\|\sum_{i=1}^m e^{\delta_i} K_{i} w - y\right\|_2^2
+ \alpha \sum_{i=1}^m e^{\delta_i} w^\top K_{i} w.\]</div>
<p>This model is called weighted kernel ridge regresion. The log-kernel-weights
<span class="math notranslate nohighlight">\(\delta_i\)</span> are here fixed. When all the targets use the same
log-kernel-weights, a single weighted kernel can be precomputed and used in a
kernel ridge regression. However, when the log-kernel-weights are different for
each target, the kernel sum cannot be precomputed, and the model requires some
specific algorithms to be fit.</p>
<div class="admonition-this-model-is-implemented-in admonition">
<p class="admonition-title">This model is implemented in</p>
<ul class="simple">
<li><p><code class="xref py py-class docutils literal notranslate"><span class="pre">WeightedKernelRidgeCV</span></code> (scikit-learn-compatible estimator)</p></li>
<li><p><a class="reference internal" href="_generated/himalaya.kernel_ridge.solve_weighted_kernel_ridge_gradient_descent.html#himalaya.kernel_ridge.solve_weighted_kernel_ridge_gradient_descent" title="himalaya.kernel_ridge.solve_weighted_kernel_ridge_gradient_descent"><code class="xref py py-func docutils literal notranslate"><span class="pre">solve_weighted_kernel_ridge_gradient_descent()</span></code></a> (function)</p></li>
<li><p><a class="reference internal" href="_generated/himalaya.kernel_ridge.solve_weighted_kernel_ridge_conjugate_gradient.html#himalaya.kernel_ridge.solve_weighted_kernel_ridge_conjugate_gradient" title="himalaya.kernel_ridge.solve_weighted_kernel_ridge_conjugate_gradient"><code class="xref py py-func docutils literal notranslate"><span class="pre">solve_weighted_kernel_ridge_conjugate_gradient()</span></code></a> (function)</p></li>
<li><p><a class="reference internal" href="_generated/himalaya.kernel_ridge.solve_weighted_kernel_ridge_neumann_series.html#himalaya.kernel_ridge.solve_weighted_kernel_ridge_neumann_series" title="himalaya.kernel_ridge.solve_weighted_kernel_ridge_neumann_series"><code class="xref py py-func docutils literal notranslate"><span class="pre">solve_weighted_kernel_ridge_neumann_series()</span></code></a> (function)</p></li>
</ul>
</div>
</section>
<section id="multiplekernelridgecv">
<h2>MultipleKernelRidgeCV<a class="headerlink" href="#multiplekernelridgecv" title="Permalink to this headline">¶</a></h2>
<p>In weighted kernel ridge regression, when the log-kernel-weights
<span class="math notranslate nohighlight">\(\delta_i\)</span> are unknown, we can learn them over cross-validation. This
model is called multiple-kernel ridge regression. When the kernels are defined
by <span class="math notranslate nohighlight">\(K_i = X_i X_i^\top\)</span> for different groups of features <span class="math notranslate nohighlight">\(X_i\)</span>,
multiple-kernel ridge regression is equivalent with group-ridge regression
(aka banded ridge regression).</p>
<div class="admonition-this-model-is-implemented-in admonition">
<p class="admonition-title">This model is implemented in</p>
<ul class="simple">
<li><p><a class="reference internal" href="_generated/himalaya.kernel_ridge.MultipleKernelRidgeCV.html#himalaya.kernel_ridge.MultipleKernelRidgeCV" title="himalaya.kernel_ridge.MultipleKernelRidgeCV"><code class="xref py py-class docutils literal notranslate"><span class="pre">MultipleKernelRidgeCV</span></code></a> (scikit-learn-compatible estimator)</p></li>
<li><p><a class="reference internal" href="_generated/himalaya.kernel_ridge.solve_multiple_kernel_ridge_hyper_gradient.html#himalaya.kernel_ridge.solve_multiple_kernel_ridge_hyper_gradient" title="himalaya.kernel_ridge.solve_multiple_kernel_ridge_hyper_gradient"><code class="xref py py-func docutils literal notranslate"><span class="pre">solve_multiple_kernel_ridge_hyper_gradient()</span></code></a> (function)</p></li>
<li><p><a class="reference internal" href="_generated/himalaya.kernel_ridge.solve_multiple_kernel_ridge_random_search.html#himalaya.kernel_ridge.solve_multiple_kernel_ridge_random_search" title="himalaya.kernel_ridge.solve_multiple_kernel_ridge_random_search"><code class="xref py py-func docutils literal notranslate"><span class="pre">solve_multiple_kernel_ridge_random_search()</span></code></a> (function)</p></li>
</ul>
</div>
</section>
<section id="model-flowchart">
<h2>Model flowchart<a class="headerlink" href="#model-flowchart" title="Permalink to this headline">¶</a></h2>
<p>The following flowchart can be used as a guide to select the right estimator.</p>
<div class="mermaid">
            graph TD;
  A(How many feature space ?)
  O(Data size ?)
  M(Data size ?)
  OR(Hyperparameters ?)
  OK(Hyperparameters ?)
  MR(Hyperparameters ?)
  MK(Hyperparameters ?)

  A-- one--&gt;O;
  A--multiple--&gt;M;
  O--more samples--&gt;OR;
  O--more features--&gt;OK;
  M--more samples--&gt;MR;
  M--more features--&gt;MK;

  OK--known--&gt;OKH[KernelRidge];
  OK--unknown--&gt;OKCV[KernelRidgeCV];
  OR--known--&gt;ORH[Ridge];
  OR--unknown--&gt;ORCV[RidgeCV];
  MK--known--&gt;MKH[WeightedKernelRidge];
  MK--unknown--&gt;MKCV[MultipleKernelRidgeCV];

  MR--unknown--&gt;MRCV[BandedRidgeCV];
  MR--known--&gt;MKH;

  classDef fork fill:#FFDC97
  class A,O,M,OR,OK,MR,MK fork;

  classDef leaf fill:#ABBBE1
  class ORH,OKH,MRH,MKH leaf;
  class ORCV,OKCV,MRCV,MKCV leaf;
        </div><section id="references">
<h3>References<a class="headerlink" href="#references" title="Permalink to this headline">¶</a></h3>
<dl class="footnote brackets">
<dt class="label" id="id4"><span class="brackets"><a class="fn-backref" href="#id1">1</a></span></dt>
<dd><p>Hoerl, A. E., &amp; Kennard, R. W. (1970). Ridge regression: Biased
estimation for nonorthogonal problems. Technometrics, 12(1), 55-67.</p>
</dd>
<dt class="label" id="id5"><span class="brackets"><a class="fn-backref" href="#id2">2</a></span></dt>
<dd><p>Saunders, C., Gammerman, A., &amp; Vovk, V. (1998). Ridge regression
learning algorithm in dual variables.</p>
</dd>
<dt class="label" id="id6"><span class="brackets"><a class="fn-backref" href="#id3">3</a></span></dt>
<dd><p>Nunez-Elizalde, A. O., Huth, A. G., &amp; Gallant, J. L. (2019). Voxelwise
encoding models with non-spherical multivariate normal priors. Neuroimage,
197, 482-492.</p>
</dd>
</dl>
</section>
</section>
</section>


          </div>
          
        </div>
      </div>
    <div class="clearer"></div>
  </div>
    <div class="footer">
      &copy;2020, Gallant lab.
      
      |
      Powered by <a href="http://sphinx-doc.org/">Sphinx 4.5.0</a>
      &amp; <a href="https://github.com/bitprophet/alabaster">Alabaster 0.7.12</a>
      
      |
      <a href="_sources/models.rst.txt"
          rel="nofollow">Page source</a>
    </div>

    

    
  </body>
</html>