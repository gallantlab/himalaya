
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Model descriptions &#8212; Himalaya 0.3.3 documentation</title>
    <link rel="stylesheet" type="text/css" href="_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="_static/alabaster.css" />
    <link rel="stylesheet" type="text/css" href="_static/gallery.css" />
    <link rel="stylesheet" type="text/css" href="_static/gallery-binder.css" />
    <link rel="stylesheet" type="text/css" href="_static/gallery-dataframe.css" />
    <link rel="stylesheet" type="text/css" href="_static/gallery-rendered-html.css" />
    <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/doctools.js"></script>
    <script async="async" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Troubleshooting" href="troubleshooting.html" />
    <link rel="prev" title="Getting started" href="getting_started.html" />
   
  <link rel="stylesheet" href="_static/custom.css" type="text/css" />
  
  
  <meta name="viewport" content="width=device-width, initial-scale=0.9, maximum-scale=0.9" />

  </head><body>
  <div class="document">
    
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
<p class="logo">
  <a href="index.html">
    <img class="logo" src="_static/logo.svg" alt="Logo"/>
    
  </a>
</p>






<p>
<iframe src="https://ghbtns.com/github-btn.html?user=gallantlab&repo=himalaya&type=star&count=true&size=large&v=2"
  allowtransparency="true" frameborder="0" scrolling="0" width="200px" height="35px"></iframe>
</p>





<div class="relations">
<h3>Related Topics</h3>
<ul>
  <li><a href="index.html">Documentation overview</a><ul>
      <li>Previous: <a href="getting_started.html" title="previous chapter">Getting started</a></li>
      <li>Next: <a href="troubleshooting.html" title="next chapter">Troubleshooting</a></li>
  </ul></li>
</ul>
</div><h3>Navigation</h3>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="getting_started.html">Getting started</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Model descriptions</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#ridge">Ridge</a></li>
<li class="toctree-l2"><a class="reference internal" href="#kernelridge">KernelRidge</a></li>
<li class="toctree-l2"><a class="reference internal" href="#ridgecv-and-kernelridgecv">RidgeCV and KernelRidgeCV</a></li>
<li class="toctree-l2"><a class="reference internal" href="#groupridgecv-bandedridgecv">GroupRidgeCV / BandedRidgeCV</a></li>
<li class="toctree-l2"><a class="reference internal" href="#weightedkernelridge">WeightedKernelRidge</a></li>
<li class="toctree-l2"><a class="reference internal" href="#multiplekernelridgecv">MultipleKernelRidgeCV</a></li>
<li class="toctree-l2"><a class="reference internal" href="#sparsegrouplassocv">SparseGroupLassoCV</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="troubleshooting.html">Troubleshooting</a></li>
<li class="toctree-l1"><a class="reference internal" href="api.html">API Documentation</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="_auto_examples/index.html">Gallery of examples</a></li>
</ul>


<div id="searchbox" style="display: none" role="search">
  <h3 id="searchlabel">Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="search.html" method="get">
      <input type="text" name="q" aria-labelledby="searchlabel" autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false"/>
      <input type="submit" value="Go" />
    </form>
    </div>
</div>
<script>$('#searchbox').show(0);</script>
        </div>
      </div>
      <div class="documentwrapper">
        <div class="bodywrapper">
          

          <div class="body" role="main">
            
  <div class="section" id="model-descriptions">
<h1>Model descriptions<a class="headerlink" href="#model-descriptions" title="Permalink to this headline">¶</a></h1>
<p>This package implements a number of models.</p>
<div class="section" id="ridge">
<h2>Ridge<a class="headerlink" href="#ridge" title="Permalink to this headline">¶</a></h2>
<p>Let <span class="math notranslate nohighlight">\(X\in \mathbb{R}^{n\times p}\)</span> be a feature matrix with <span class="math notranslate nohighlight">\(n\)</span>
samples and <span class="math notranslate nohighlight">\(p\)</span> features,  <span class="math notranslate nohighlight">\(y\in \mathbb{R}^n\)</span> a target vector, and
<span class="math notranslate nohighlight">\(\alpha &gt; 0\)</span> a fixed regularization hyperparameter. Ridge regression
<a class="footnote-reference brackets" href="#id4" id="id1">1</a> defines the weight vector <span class="math notranslate nohighlight">\(b^*\in \mathbb{R}^p\)</span> as</p>
<div class="math notranslate nohighlight">
\[b^* = \arg\min_b \|Xb - y\|_2^2 + \alpha \|b\|_2^2.\]</div>
<p>The equation has a  closed-form solution <span class="math notranslate nohighlight">\(b^* = M y\)</span>, where <span class="math notranslate nohighlight">\(M =
(X^\top X + \alpha I_p)^{-1}X^\top \in  \mathbb{R}^{p \times n}\)</span>.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This model is implemented in a scikit-learn-compatible estimator
<a class="reference internal" href="_generated/himalaya.ridge.Ridge.html#himalaya.ridge.Ridge" title="himalaya.ridge.Ridge"><code class="xref py py-class docutils literal notranslate"><span class="pre">Ridge</span></code></a>, or through the function
<a class="reference internal" href="_generated/himalaya.ridge.solve_ridge_svd.html#himalaya.ridge.solve_ridge_svd" title="himalaya.ridge.solve_ridge_svd"><code class="xref py py-func docutils literal notranslate"><span class="pre">solve_ridge_svd()</span></code></a>.</p>
</div>
</div>
<div class="section" id="kernelridge">
<h2>KernelRidge<a class="headerlink" href="#kernelridge" title="Permalink to this headline">¶</a></h2>
<p>By the Woodbury matrix identity, <span class="math notranslate nohighlight">\(b^*\)</span> can be written as <span class="math notranslate nohighlight">\(b^* =
X^\top(XX^\top + \alpha I_n)^{-1}y\)</span>, or <span class="math notranslate nohighlight">\(b^* = X^\top w^*\)</span> for some
<span class="math notranslate nohighlight">\(w^*\in \mathbb{R}^n\)</span>. Noting the linear kernel <span class="math notranslate nohighlight">\(K = X X^\top \in
\mathbb{R}^{n\times n}\)</span>, this leads to the <em>equivalent</em> formulation</p>
<div class="math notranslate nohighlight">
\[w^* = \arg\min_w \|Kw - y\|_2^2 + \alpha w^\top Kw.\]</div>
<p>This model can be extended to arbitrary positive semidefinite kernels
<span class="math notranslate nohighlight">\(K\)</span>, leading to the more general kernel ridge regression <a class="footnote-reference brackets" href="#id5" id="id2">2</a>.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This model is implemented in a scikit-learn-compatible estimator
<a class="reference internal" href="_generated/himalaya.kernel_ridge.KernelRidge.html#himalaya.kernel_ridge.KernelRidge" title="himalaya.kernel_ridge.KernelRidge"><code class="xref py py-class docutils literal notranslate"><span class="pre">KernelRidge</span></code></a>, or through the functions
<a class="reference internal" href="_generated/himalaya.kernel_ridge.solve_kernel_ridge_eigenvalues.html#himalaya.kernel_ridge.solve_kernel_ridge_eigenvalues" title="himalaya.kernel_ridge.solve_kernel_ridge_eigenvalues"><code class="xref py py-func docutils literal notranslate"><span class="pre">solve_kernel_ridge_eigenvalues()</span></code></a>,
<a class="reference internal" href="_generated/himalaya.kernel_ridge.solve_kernel_ridge_gradient_descent.html#himalaya.kernel_ridge.solve_kernel_ridge_gradient_descent" title="himalaya.kernel_ridge.solve_kernel_ridge_gradient_descent"><code class="xref py py-func docutils literal notranslate"><span class="pre">solve_kernel_ridge_gradient_descent()</span></code></a>, and
<a class="reference internal" href="_generated/himalaya.kernel_ridge.solve_kernel_ridge_conjugate_gradient.html#himalaya.kernel_ridge.solve_kernel_ridge_conjugate_gradient" title="himalaya.kernel_ridge.solve_kernel_ridge_conjugate_gradient"><code class="xref py py-func docutils literal notranslate"><span class="pre">solve_kernel_ridge_conjugate_gradient()</span></code></a>.</p>
</div>
</div>
<div class="section" id="ridgecv-and-kernelridgecv">
<h2>RidgeCV and KernelRidgeCV<a class="headerlink" href="#ridgecv-and-kernelridgecv" title="Permalink to this headline">¶</a></h2>
<p>In practice, because the ridge regression and kernel ridge regression
hyperparameter <span class="math notranslate nohighlight">\(\alpha\)</span> is unknown, it is typically selected through a
grid-search with cross-validation. In cross-validation, we split the data set
into a training set <span class="math notranslate nohighlight">\((X_{train}, y_{train})\)</span> and a validation set
<span class="math notranslate nohighlight">\((X_{val}, y_{val})\)</span>. Then, we train the model on the training set, and
evaluate the generalization performance on the validation set. We perform this
process for multiple hyperparameter candidates <span class="math notranslate nohighlight">\(\alpha\)</span>, typically
defined over a grid of log-spaced values. Finally, we keep the candidate
leading to the best generalization performance, as measured by the validation
loss, averaged over all cross-validation splits.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>These models are implemented in scikit-learn-compatible estimators
<a class="reference internal" href="_generated/himalaya.ridge.RidgeCV.html#himalaya.ridge.RidgeCV" title="himalaya.ridge.RidgeCV"><code class="xref py py-class docutils literal notranslate"><span class="pre">RidgeCV</span></code></a> and
<a class="reference internal" href="_generated/himalaya.kernel_ridge.KernelRidgeCV.html#himalaya.kernel_ridge.KernelRidgeCV" title="himalaya.kernel_ridge.KernelRidgeCV"><code class="xref py py-class docutils literal notranslate"><span class="pre">KernelRidgeCV</span></code></a>, or through the functions
<a class="reference internal" href="_generated/himalaya.ridge.solve_ridge_cv_svd.html#himalaya.ridge.solve_ridge_cv_svd" title="himalaya.ridge.solve_ridge_cv_svd"><code class="xref py py-func docutils literal notranslate"><span class="pre">solve_ridge_cv_svd()</span></code></a> and
<a class="reference internal" href="_generated/himalaya.kernel_ridge.solve_kernel_ridge_cv_eigenvalues.html#himalaya.kernel_ridge.solve_kernel_ridge_cv_eigenvalues" title="himalaya.kernel_ridge.solve_kernel_ridge_cv_eigenvalues"><code class="xref py py-func docutils literal notranslate"><span class="pre">solve_kernel_ridge_cv_eigenvalues()</span></code></a>.</p>
</div>
</div>
<div class="section" id="groupridgecv-bandedridgecv">
<h2>GroupRidgeCV / BandedRidgeCV<a class="headerlink" href="#groupridgecv-bandedridgecv" title="Permalink to this headline">¶</a></h2>
<p>In some applications, features are naturally grouped into groups (or feature
spaces). To adapt the regularization level to each feature space, ridge
regression can be extended to group-regularized ridge regression (also known
as banded ridge regression <a class="footnote-reference brackets" href="#id6" id="id3">3</a>). In this model, a separate hyperparameter is
optimized for each feature space:</p>
<div class="math notranslate nohighlight">
\[b^* = \arg\min_b \|\sum_{i=1}^m X_i b_i - y\|_2^2 + \sum_{i=1}^m \alpha_i \|b_i\|_2^2.\]</div>
<p>This is equivalent to solving a ridge regression:</p>
<div class="math notranslate nohighlight">
\[b^* = \arg\min_b \|Z b - Y\|_2^2 + \|b\|_2^2\]</div>
<p>where the feature space <span class="math notranslate nohighlight">\(X_i\)</span> is scaled by a group scaling
<span class="math notranslate nohighlight">\(Z_i = e^{\delta_i / 2} X_i\)</span>. The hyperparameters <span class="math notranslate nohighlight">\(\delta_i\)</span> are
then learned over cross-validation.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This model is implemented in a scikit-learn-compatible estimator
<a class="reference internal" href="_generated/himalaya.ridge.GroupRidgeCV.html#himalaya.ridge.GroupRidgeCV" title="himalaya.ridge.GroupRidgeCV"><code class="xref py py-class docutils literal notranslate"><span class="pre">GroupRidgeCV</span></code></a>, or through the function
<a class="reference internal" href="_generated/himalaya.ridge.solve_group_ridge_random_search.html#himalaya.ridge.solve_group_ridge_random_search" title="himalaya.ridge.solve_group_ridge_random_search"><code class="xref py py-func docutils literal notranslate"><span class="pre">solve_group_ridge_random_search()</span></code></a>. See also
<a class="reference internal" href="_generated/himalaya.kernel_ridge.MultipleKernelRidgeCV.html#himalaya.kernel_ridge.MultipleKernelRidgeCV" title="himalaya.kernel_ridge.MultipleKernelRidgeCV"><code class="xref py py-class docutils literal notranslate"><span class="pre">MultipleKernelRidgeCV</span></code></a>, which is equivalent to
group-regularization ridge regression when using one linear kernel per group
of features.</p>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>“Group ridge regression” is also sometimes called “Banded ridge regression”.</p>
</div>
</div>
<div class="section" id="weightedkernelridge">
<h2>WeightedKernelRidge<a class="headerlink" href="#weightedkernelridge" title="Permalink to this headline">¶</a></h2>
<p>Kernel ridge regression can be naturally extend to a weighted sum of multiple
kernels, <span class="math notranslate nohighlight">\(K = \sum_{i=1}^m e^{\delta_i} K_i\)</span>. A typical example is to use
<span class="math notranslate nohighlight">\(K_i = X_i X_i^\top\)</span> for different subsets of features <span class="math notranslate nohighlight">\(X_i\)</span>.
The model becomes:</p>
<div class="math notranslate nohighlight">
\[w^* = \arg\min_w \left\|\sum_{i=1}^m e^{\delta_i} K_{i} w - y\right\|_2^2
+ \alpha \sum_{i=1}^m e^{\delta_i} w^\top K_{i} w.\]</div>
<p>Contrarily to <a class="reference internal" href="_generated/himalaya.kernel_ridge.MultipleKernelRidgeCV.html#himalaya.kernel_ridge.MultipleKernelRidgeCV" title="himalaya.kernel_ridge.MultipleKernelRidgeCV"><code class="xref py py-class docutils literal notranslate"><span class="pre">MultipleKernelRidgeCV</span></code></a>, this model
does not optimize the log kernel-weights <span class="math notranslate nohighlight">\(\delta_i\)</span>. However, it is not
equivalent to <a class="reference internal" href="_generated/himalaya.kernel_ridge.KernelRidge.html#himalaya.kernel_ridge.KernelRidge" title="himalaya.kernel_ridge.KernelRidge"><code class="xref py py-class docutils literal notranslate"><span class="pre">KernelRidge</span></code></a>, since the log
kernel-weights <span class="math notranslate nohighlight">\(\delta_i\)</span> can be different for each target, therefore the
kernel sum is not precomputed.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This model is implemented in a scikit-learn-compatible estimator
<code class="xref py py-class docutils literal notranslate"><span class="pre">WeightedKernelRidgeCV</span></code>, or through the
functions
<a class="reference internal" href="_generated/himalaya.kernel_ridge.solve_weighted_kernel_ridge_gradient_descent.html#himalaya.kernel_ridge.solve_weighted_kernel_ridge_gradient_descent" title="himalaya.kernel_ridge.solve_weighted_kernel_ridge_gradient_descent"><code class="xref py py-func docutils literal notranslate"><span class="pre">solve_weighted_kernel_ridge_gradient_descent()</span></code></a>,
<a class="reference internal" href="_generated/himalaya.kernel_ridge.solve_weighted_kernel_ridge_conjugate_gradient.html#himalaya.kernel_ridge.solve_weighted_kernel_ridge_conjugate_gradient" title="himalaya.kernel_ridge.solve_weighted_kernel_ridge_conjugate_gradient"><code class="xref py py-func docutils literal notranslate"><span class="pre">solve_weighted_kernel_ridge_conjugate_gradient()</span></code></a>,
and
<a class="reference internal" href="_generated/himalaya.kernel_ridge.solve_weighted_kernel_ridge_neumann_series.html#himalaya.kernel_ridge.solve_weighted_kernel_ridge_neumann_series" title="himalaya.kernel_ridge.solve_weighted_kernel_ridge_neumann_series"><code class="xref py py-func docutils literal notranslate"><span class="pre">solve_weighted_kernel_ridge_neumann_series()</span></code></a>.</p>
</div>
</div>
<div class="section" id="multiplekernelridgecv">
<h2>MultipleKernelRidgeCV<a class="headerlink" href="#multiplekernelridgecv" title="Permalink to this headline">¶</a></h2>
<p>In weighted kernel ridge regression, when the log kernel-weights
<span class="math notranslate nohighlight">\(\delta_i\)</span> are unknown, we can learn them over cross-validation.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This model is implemented in a scikit-learn-compatible estimator
<a class="reference internal" href="_generated/himalaya.kernel_ridge.MultipleKernelRidgeCV.html#himalaya.kernel_ridge.MultipleKernelRidgeCV" title="himalaya.kernel_ridge.MultipleKernelRidgeCV"><code class="xref py py-class docutils literal notranslate"><span class="pre">MultipleKernelRidgeCV</span></code></a>, or through the
functions
<a class="reference internal" href="_generated/himalaya.kernel_ridge.solve_multiple_kernel_ridge_hyper_gradient.html#himalaya.kernel_ridge.solve_multiple_kernel_ridge_hyper_gradient" title="himalaya.kernel_ridge.solve_multiple_kernel_ridge_hyper_gradient"><code class="xref py py-func docutils literal notranslate"><span class="pre">solve_multiple_kernel_ridge_hyper_gradient()</span></code></a>,
and <a class="reference internal" href="_generated/himalaya.kernel_ridge.solve_multiple_kernel_ridge_random_search.html#himalaya.kernel_ridge.solve_multiple_kernel_ridge_random_search" title="himalaya.kernel_ridge.solve_multiple_kernel_ridge_random_search"><code class="xref py py-func docutils literal notranslate"><span class="pre">solve_multiple_kernel_ridge_random_search()</span></code></a>.</p>
</div>
</div>
<div class="section" id="sparsegrouplassocv">
<h2>SparseGroupLassoCV<a class="headerlink" href="#sparsegrouplassocv" title="Permalink to this headline">¶</a></h2>
<p>…</p>
<div class="section" id="references">
<h3>References<a class="headerlink" href="#references" title="Permalink to this headline">¶</a></h3>
<dl class="footnote brackets">
<dt class="label" id="id4"><span class="brackets"><a class="fn-backref" href="#id1">1</a></span></dt>
<dd><p>Hoerl, A. E., &amp; Kennard, R. W. (1970). Ridge regression: Biased
estimation for nonorthogonal problems. Technometrics, 12(1), 55-67.</p>
</dd>
<dt class="label" id="id5"><span class="brackets"><a class="fn-backref" href="#id2">2</a></span></dt>
<dd><p>Saunders, C., Gammerman, A., &amp; Vovk, V. (1998). Ridge regression
learning algorithm in dual variables.</p>
</dd>
<dt class="label" id="id6"><span class="brackets"><a class="fn-backref" href="#id3">3</a></span></dt>
<dd><p>Nunez-Elizalde, A. O., Huth, A. G., &amp; Gallant, J. L. (2019). Voxelwise
encoding models with non-spherical multivariate normal priors. Neuroimage,
197, 482-492.</p>
</dd>
</dl>
</div>
</div>
</div>


          </div>
          
        </div>
      </div>
    <div class="clearer"></div>
  </div>
    <div class="footer">
      &copy;2020, Gallant lab.
      
      |
      Powered by <a href="http://sphinx-doc.org/">Sphinx 4.1.2</a>
      &amp; <a href="https://github.com/bitprophet/alabaster">Alabaster 0.7.12</a>
      
      |
      <a href="_sources/models.rst.txt"
          rel="nofollow">Page source</a>
    </div>

    

    
  </body>
</html>