
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Multiple kernel ridge regression &#8212; Himalaya 0.3.1 documentation</title>
    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/alabaster.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/gallery.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/gallery-binder.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/gallery-dataframe.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/gallery-rendered-html.css" />
    <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
    <script src="../../_static/jquery.js"></script>
    <script src="../../_static/underscore.js"></script>
    <script src="../../_static/doctools.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="Multiple kernel ridge with scikit-learn API" href="plot_mkr_sklearn_api.html" />
    <link rel="prev" title="Fitting a model on GPU" href="../kernel_ridge/plot_model_on_gpu.py.html" />
   
  <link rel="stylesheet" href="../../_static/custom.css" type="text/css" />
  
  
  <meta name="viewport" content="width=device-width, initial-scale=0.9, maximum-scale=0.9" />

  </head><body>
  <div class="document">
    
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
<p class="logo">
  <a href="../../index.html">
    <img class="logo" src="../../_static/logo.svg" alt="Logo"/>
    
  </a>
</p>






<p>
<iframe src="https://ghbtns.com/github-btn.html?user=gallantlab&repo=himalaya&type=star&count=true&size=large&v=2"
  allowtransparency="true" frameborder="0" scrolling="0" width="200px" height="35px"></iframe>
</p>





<div class="relations">
<h3>Related Topics</h3>
<ul>
  <li><a href="../../index.html">Documentation overview</a><ul>
  <li><a href="../index.html">Gallery of examples</a><ul>
      <li>Previous: <a href="../kernel_ridge/plot_model_on_gpu.py.html" title="previous chapter">Fitting a model on GPU</a></li>
      <li>Next: <a href="plot_mkr_sklearn_api.html" title="next chapter">Multiple kernel ridge with scikit-learn API</a></li>
  </ul></li>
  </ul></li>
</ul>
</div><h3>Navigation</h3>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../getting_started.html">Getting started</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../models.html">Model descriptions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../troubleshooting.html">Troubleshooting</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../api.html">API Documentation</a></li>
</ul>
<ul class="current">
<li class="toctree-l1 current"><a class="reference internal" href="../index.html">Gallery of examples</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="../index.html#kernel-ridge-regression">Kernel ridge regression</a></li>
<li class="toctree-l2 current"><a class="reference internal" href="../index.html#multiple-kernel-ridge-regression">Multiple kernel ridge regression</a></li>
</ul>
</li>
</ul>


<div id="searchbox" style="display: none" role="search">
  <h3 id="searchlabel">Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="../../search.html" method="get">
      <input type="text" name="q" aria-labelledby="searchlabel" autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false"/>
      <input type="submit" value="Go" />
    </form>
    </div>
</div>
<script>$('#searchbox').show(0);</script>
        </div>
      </div>
      <div class="documentwrapper">
        <div class="bodywrapper">
          

          <div class="body" role="main">
            
  <div class="sphx-glr-download-link-note admonition note">
<p class="admonition-title">Note</p>
<p>Click <a class="reference internal" href="#sphx-glr-download-auto-examples-multiple-kernel-ridge-plot-mkr-random-search-py"><span class="std std-ref">here</span></a>
to download the full example code</p>
</div>
<div class="sphx-glr-example-title section" id="multiple-kernel-ridge-regression">
<span id="sphx-glr-auto-examples-multiple-kernel-ridge-plot-mkr-random-search-py"></span><h1>Multiple kernel ridge regression<a class="headerlink" href="#multiple-kernel-ridge-regression" title="Permalink to this headline">¶</a></h1>
<p>This example demonstrates how to solve multiple kernel ridge regression.
It uses random search and cross validation to select optimal hyperparameters.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>

<span class="kn">from</span> <span class="nn">himalaya.backend</span> <span class="kn">import</span> <span class="n">set_backend</span>
<span class="kn">from</span> <span class="nn">himalaya.kernel_ridge</span> <span class="kn">import</span> <span class="n">solve_multiple_kernel_ridge_random_search</span>
<span class="kn">from</span> <span class="nn">himalaya.kernel_ridge</span> <span class="kn">import</span> <span class="n">predict_and_score_weighted_kernel_ridge</span>
<span class="kn">from</span> <span class="nn">himalaya.scoring</span> <span class="kn">import</span> <span class="n">r2_score_split</span>
<span class="kn">from</span> <span class="nn">himalaya.viz</span> <span class="kn">import</span> <span class="n">plot_alphas_diagnostic</span>
</pre></div>
</div>
<p>In this example, we use the <code class="docutils literal notranslate"><span class="pre">cupy</span></code> backend, and fit the model on GPU.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">backend</span> <span class="o">=</span> <span class="n">set_backend</span><span class="p">(</span><span class="s2">&quot;cupy&quot;</span><span class="p">)</span>
</pre></div>
</div>
<div class="section" id="generate-a-random-dataset">
<h2>Generate a random dataset<a class="headerlink" href="#generate-a-random-dataset" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p>Xs_train : list of arrays of shape (n_samples_train, n_features)</p></li>
<li><p>Xs_test : list of arrays of shape (n_samples_test, n_features)</p></li>
<li><p>Y_train : array of shape (n_samples_train, n_targets)</p></li>
<li><p>Y_test : array of shape (n_repeat, n_samples_test, n_targets)</p></li>
</ul>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">n_samples_train</span> <span class="o">=</span> <span class="mi">1000</span>
<span class="n">n_samples_test</span> <span class="o">=</span> <span class="mi">300</span>
<span class="n">n_targets</span> <span class="o">=</span> <span class="mi">1000</span>
<span class="n">n_features_list</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1000</span><span class="p">,</span> <span class="mi">1000</span><span class="p">,</span> <span class="mi">500</span><span class="p">]</span>

<span class="n">Xs_train</span> <span class="o">=</span> <span class="p">[</span>
    <span class="n">backend</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">n_samples_train</span><span class="p">,</span> <span class="n">n_features</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">n_features</span> <span class="ow">in</span> <span class="n">n_features_list</span>
<span class="p">]</span>
<span class="n">Xs_test</span> <span class="o">=</span> <span class="p">[</span>
    <span class="n">backend</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">n_samples_test</span><span class="p">,</span> <span class="n">n_features</span><span class="p">)</span> <span class="k">for</span> <span class="n">n_features</span> <span class="ow">in</span> <span class="n">n_features_list</span>
<span class="p">]</span>
<span class="n">ws</span> <span class="o">=</span> <span class="p">[</span>
    <span class="n">backend</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">n_features</span><span class="p">,</span> <span class="n">n_targets</span><span class="p">)</span> <span class="o">/</span> <span class="n">n_features</span>
    <span class="k">for</span> <span class="n">n_features</span> <span class="ow">in</span> <span class="n">n_features_list</span>
<span class="p">]</span>
<span class="n">Y_train</span> <span class="o">=</span> <span class="n">backend</span><span class="o">.</span><span class="n">stack</span><span class="p">([</span><span class="n">X</span> <span class="o">@</span> <span class="n">w</span> <span class="k">for</span> <span class="n">X</span><span class="p">,</span> <span class="n">w</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">Xs_train</span><span class="p">,</span> <span class="n">ws</span><span class="p">)])</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="n">Y_test</span> <span class="o">=</span> <span class="n">backend</span><span class="o">.</span><span class="n">stack</span><span class="p">([</span><span class="n">X</span> <span class="o">@</span> <span class="n">w</span> <span class="k">for</span> <span class="n">X</span><span class="p">,</span> <span class="n">w</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">Xs_test</span><span class="p">,</span> <span class="n">ws</span><span class="p">)])</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
</pre></div>
</div>
<p>Optional: Add some arbitrary scalings per kernel</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">if</span> <span class="kc">True</span><span class="p">:</span>
    <span class="n">scalings</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.2</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span>
    <span class="n">Xs_train</span> <span class="o">=</span> <span class="p">[</span><span class="n">X</span> <span class="o">*</span> <span class="n">scaling</span> <span class="k">for</span> <span class="n">X</span><span class="p">,</span> <span class="n">scaling</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">Xs_train</span><span class="p">,</span> <span class="n">scalings</span><span class="p">)]</span>
    <span class="n">Xs_test</span> <span class="o">=</span> <span class="p">[</span><span class="n">X</span> <span class="o">*</span> <span class="n">scaling</span> <span class="k">for</span> <span class="n">X</span><span class="p">,</span> <span class="n">scaling</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">Xs_test</span><span class="p">,</span> <span class="n">scalings</span><span class="p">)]</span>

<span class="n">Y_train</span> <span class="o">-=</span> <span class="n">Y_train</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="n">Y_test</span> <span class="o">-=</span> <span class="n">Y_test</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="precompute-the-linear-kernels">
<h2>Precompute the linear kernels<a class="headerlink" href="#precompute-the-linear-kernels" title="Permalink to this headline">¶</a></h2>
<p>We also cast them to float32.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Ks_train</span> <span class="o">=</span> <span class="n">backend</span><span class="o">.</span><span class="n">stack</span><span class="p">([</span><span class="n">X_train</span> <span class="o">@</span> <span class="n">X_train</span><span class="o">.</span><span class="n">T</span> <span class="k">for</span> <span class="n">X_train</span> <span class="ow">in</span> <span class="n">Xs_train</span><span class="p">])</span>
<span class="n">Ks_train</span> <span class="o">=</span> <span class="n">backend</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">Ks_train</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">backend</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">Y_train</span> <span class="o">=</span> <span class="n">backend</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">Y_train</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">backend</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>

<span class="n">Ks_test</span> <span class="o">=</span> <span class="n">backend</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span>
    <span class="p">[</span><span class="n">X_test</span> <span class="o">@</span> <span class="n">X_train</span><span class="o">.</span><span class="n">T</span> <span class="k">for</span> <span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">Xs_train</span><span class="p">,</span> <span class="n">Xs_test</span><span class="p">)])</span>
<span class="n">Ks_test</span> <span class="o">=</span> <span class="n">backend</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">Ks_test</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">backend</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">Y_test</span> <span class="o">=</span> <span class="n">backend</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">Y_test</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">backend</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="run-the-solver-using-random-search">
<h2>Run the solver, using random search<a class="headerlink" href="#run-the-solver-using-random-search" title="Permalink to this headline">¶</a></h2>
<p>This method should work fine for
small number of kernels (&lt; 20). The larger the number of kenels, the larger
we need to sample the hyperparameter space (i.e. increasing <code class="docutils literal notranslate"><span class="pre">n_iter</span></code>).</p>
<p>Here we use 100 iterations to have a reasonably fast example (~40 sec).
To have a better convergence, we probably need more iterations.
Note that there is currently no stopping criterion in this method.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">n_iter</span> <span class="o">=</span> <span class="mi">100</span>
</pre></div>
</div>
<p>Grid of regularization parameters.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">alphas</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">logspace</span><span class="p">(</span><span class="o">-</span><span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">21</span><span class="p">)</span>
</pre></div>
</div>
<p>Batch parameters are used to reduce the necessary GPU memory. A larger value
will be a bit faster, but the solver might crash if it runs out of memory.
Optimal values depend on the size of your dataset.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">n_targets_batch</span> <span class="o">=</span> <span class="mi">1000</span>
<span class="n">n_alphas_batch</span> <span class="o">=</span> <span class="mi">20</span>
</pre></div>
</div>
<p>If <code class="docutils literal notranslate"><span class="pre">return_weights</span> <span class="pre">==</span> <span class="pre">&quot;dual&quot;</span></code>, the solver will use more memory.
To mitigate this, you can reduce <code class="docutils literal notranslate"><span class="pre">n_targets_batch</span></code> in the refit
using <code class="docutils literal notranslate"><span class="pre">`n_targets_batch_refit</span></code>.
If you don’t need the dual weights, use <code class="docutils literal notranslate"><span class="pre">return_weights</span> <span class="pre">=</span> <span class="pre">None</span></code>.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">return_weights</span> <span class="o">=</span> <span class="s1">&#39;dual&#39;</span>
<span class="n">n_targets_batch_refit</span> <span class="o">=</span> <span class="mi">200</span>
</pre></div>
</div>
<p>Run the solver. For each iteration, it will:</p>
<ul class="simple">
<li><p>sample kernel weights from a Dirichlet distribution</p></li>
<li><p>fit (n_splits * n_alphas * n_targets) ridge models</p></li>
<li><p>compute the scores on the validation set of each split</p></li>
<li><p>average the scores over splits</p></li>
<li><p>take the maximum over alphas</p></li>
<li><p>(only if you ask for the ridge weights) refit using the best alphas per
target and the entire dataset</p></li>
<li><p>return for each target the log kernel weights leading to the best CV score
(and the best weights if necessary)</p></li>
</ul>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">results</span> <span class="o">=</span> <span class="n">solve_multiple_kernel_ridge_random_search</span><span class="p">(</span>
    <span class="n">Ks</span><span class="o">=</span><span class="n">Ks_train</span><span class="p">,</span>
    <span class="n">Y</span><span class="o">=</span><span class="n">Y_train</span><span class="p">,</span>
    <span class="n">n_iter</span><span class="o">=</span><span class="n">n_iter</span><span class="p">,</span>
    <span class="n">alphas</span><span class="o">=</span><span class="n">alphas</span><span class="p">,</span>
    <span class="n">n_targets_batch</span><span class="o">=</span><span class="n">n_targets_batch</span><span class="p">,</span>
    <span class="n">return_weights</span><span class="o">=</span><span class="n">return_weights</span><span class="p">,</span>
    <span class="n">n_alphas_batch</span><span class="o">=</span><span class="n">n_alphas_batch</span><span class="p">,</span>
    <span class="n">n_targets_batch_refit</span><span class="o">=</span><span class="n">n_targets_batch_refit</span><span class="p">,</span>
    <span class="n">jitter_alphas</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>[                                        ] 0% | 0.00 sec | 100 random sampling with cv |
[                                        ] 1% | 0.45 sec | 100 random sampling with cv |
[                                        ] 2% | 0.82 sec | 100 random sampling with cv |
[.                                       ] 3% | 1.11 sec | 100 random sampling with cv |
[.                                       ] 4% | 1.40 sec | 100 random sampling with cv |
[..                                      ] 5% | 1.77 sec | 100 random sampling with cv |
[..                                      ] 6% | 2.06 sec | 100 random sampling with cv |
[..                                      ] 7% | 2.35 sec | 100 random sampling with cv |
[...                                     ] 8% | 2.64 sec | 100 random sampling with cv |
[...                                     ] 9% | 2.93 sec | 100 random sampling with cv |
[....                                    ] 10% | 3.22 sec | 100 random sampling with cv |
[....                                    ] 11% | 3.51 sec | 100 random sampling with cv |
[....                                    ] 12% | 3.80 sec | 100 random sampling with cv |
[.....                                   ] 13% | 4.09 sec | 100 random sampling with cv |
[.....                                   ] 14% | 4.38 sec | 100 random sampling with cv |
[......                                  ] 15% | 4.67 sec | 100 random sampling with cv |
[......                                  ] 16% | 4.96 sec | 100 random sampling with cv |
[......                                  ] 17% | 5.26 sec | 100 random sampling with cv |
[.......                                 ] 18% | 5.55 sec | 100 random sampling with cv |
[.......                                 ] 19% | 5.84 sec | 100 random sampling with cv |
[........                                ] 20% | 6.13 sec | 100 random sampling with cv |
[........                                ] 21% | 6.42 sec | 100 random sampling with cv |
[........                                ] 22% | 6.71 sec | 100 random sampling with cv |
[.........                               ] 23% | 7.06 sec | 100 random sampling with cv |
[.........                               ] 24% | 7.35 sec | 100 random sampling with cv |
[..........                              ] 25% | 7.64 sec | 100 random sampling with cv |
[..........                              ] 26% | 7.93 sec | 100 random sampling with cv |
[..........                              ] 27% | 8.22 sec | 100 random sampling with cv |
[...........                             ] 28% | 8.51 sec | 100 random sampling with cv |
[...........                             ] 29% | 8.80 sec | 100 random sampling with cv |
[............                            ] 30% | 9.09 sec | 100 random sampling with cv |
[............                            ] 31% | 9.42 sec | 100 random sampling with cv |
[............                            ] 32% | 9.71 sec | 100 random sampling with cv |
[.............                           ] 33% | 10.00 sec | 100 random sampling with cv |
[.............                           ] 34% | 10.29 sec | 100 random sampling with cv |
[..............                          ] 35% | 10.58 sec | 100 random sampling with cv |
[..............                          ] 36% | 10.87 sec | 100 random sampling with cv |
[..............                          ] 37% | 11.23 sec | 100 random sampling with cv |
[...............                         ] 38% | 11.52 sec | 100 random sampling with cv |
[...............                         ] 39% | 11.82 sec | 100 random sampling with cv |
[................                        ] 40% | 12.11 sec | 100 random sampling with cv |
[................                        ] 41% | 12.40 sec | 100 random sampling with cv |
[................                        ] 42% | 12.70 sec | 100 random sampling with cv |
[.................                       ] 43% | 12.99 sec | 100 random sampling with cv |
[.................                       ] 44% | 13.28 sec | 100 random sampling with cv |
[..................                      ] 45% | 13.58 sec | 100 random sampling with cv |
[..................                      ] 46% | 13.87 sec | 100 random sampling with cv |
[..................                      ] 47% | 14.16 sec | 100 random sampling with cv |
[...................                     ] 48% | 14.46 sec | 100 random sampling with cv |
[...................                     ] 49% | 14.75 sec | 100 random sampling with cv |
[....................                    ] 50% | 15.04 sec | 100 random sampling with cv |
[....................                    ] 51% | 15.40 sec | 100 random sampling with cv |
[....................                    ] 52% | 15.69 sec | 100 random sampling with cv |
[.....................                   ] 53% | 15.98 sec | 100 random sampling with cv |
[.....................                   ] 54% | 16.28 sec | 100 random sampling with cv |
[......................                  ] 55% | 16.64 sec | 100 random sampling with cv |
[......................                  ] 56% | 16.94 sec | 100 random sampling with cv |
[......................                  ] 57% | 17.28 sec | 100 random sampling with cv |
[.......................                 ] 58% | 17.58 sec | 100 random sampling with cv |
[.......................                 ] 59% | 17.85 sec | 100 random sampling with cv |
[........................                ] 60% | 18.14 sec | 100 random sampling with cv |
[........................                ] 61% | 18.44 sec | 100 random sampling with cv |
[........................                ] 62% | 18.73 sec | 100 random sampling with cv |
[.........................               ] 63% | 19.09 sec | 100 random sampling with cv |
[.........................               ] 64% | 19.39 sec | 100 random sampling with cv |
[..........................              ] 65% | 19.68 sec | 100 random sampling with cv |
[..........................              ] 66% | 19.97 sec | 100 random sampling with cv |
[..........................              ] 67% | 20.27 sec | 100 random sampling with cv |
[...........................             ] 68% | 20.56 sec | 100 random sampling with cv |
[...........................             ] 69% | 20.90 sec | 100 random sampling with cv |
[............................            ] 70% | 21.20 sec | 100 random sampling with cv |
[............................            ] 71% | 21.49 sec | 100 random sampling with cv |
[............................            ] 72% | 21.78 sec | 100 random sampling with cv |
[.............................           ] 73% | 22.16 sec | 100 random sampling with cv |
[.............................           ] 74% | 22.47 sec | 100 random sampling with cv |
[..............................          ] 75% | 22.84 sec | 100 random sampling with cv |
[..............................          ] 76% | 23.14 sec | 100 random sampling with cv |
[..............................          ] 77% | 23.44 sec | 100 random sampling with cv |
[...............................         ] 78% | 23.73 sec | 100 random sampling with cv |
[...............................         ] 79% | 24.02 sec | 100 random sampling with cv |
[................................        ] 80% | 24.32 sec | 100 random sampling with cv |
[................................        ] 81% | 24.69 sec | 100 random sampling with cv |
[................................        ] 82% | 24.99 sec | 100 random sampling with cv |
[.................................       ] 83% | 25.28 sec | 100 random sampling with cv |
[.................................       ] 84% | 25.58 sec | 100 random sampling with cv |
[..................................      ] 85% | 25.88 sec | 100 random sampling with cv |
[..................................      ] 86% | 26.18 sec | 100 random sampling with cv |
[..................................      ] 87% | 26.45 sec | 100 random sampling with cv |
[...................................     ] 88% | 26.74 sec | 100 random sampling with cv |
[...................................     ] 89% | 27.04 sec | 100 random sampling with cv |
[....................................    ] 90% | 27.34 sec | 100 random sampling with cv |
[....................................    ] 91% | 27.65 sec | 100 random sampling with cv |
[....................................    ] 92% | 27.95 sec | 100 random sampling with cv |
[.....................................   ] 93% | 28.28 sec | 100 random sampling with cv |
[.....................................   ] 94% | 28.65 sec | 100 random sampling with cv |
[......................................  ] 95% | 28.95 sec | 100 random sampling with cv |
[......................................  ] 96% | 29.25 sec | 100 random sampling with cv |
[......................................  ] 97% | 29.63 sec | 100 random sampling with cv |
[....................................... ] 98% | 29.92 sec | 100 random sampling with cv |
[....................................... ] 99% | 30.22 sec | 100 random sampling with cv |
[........................................] 100% | 30.51 sec | 100 random sampling with cv |
</pre></div>
</div>
<p>As we used the <code class="docutils literal notranslate"><span class="pre">cupy</span></code> backend, the results are <code class="docutils literal notranslate"><span class="pre">cupy</span></code> arrays, which are
on GPU. Here, we cast the results back to CPU, and to <code class="docutils literal notranslate"><span class="pre">numpy</span></code> arrays.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">deltas</span> <span class="o">=</span> <span class="n">backend</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">(</span><span class="n">results</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="n">dual_weights</span> <span class="o">=</span> <span class="n">backend</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">(</span><span class="n">results</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
<span class="n">cv_scores</span> <span class="o">=</span> <span class="n">backend</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">(</span><span class="n">results</span><span class="p">[</span><span class="mi">2</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="section" id="plot-the-convergence-curve">
<h2>Plot the convergence curve<a class="headerlink" href="#plot-the-convergence-curve" title="Permalink to this headline">¶</a></h2>
<p><code class="docutils literal notranslate"><span class="pre">cv_scores</span></code> gives the scores for each sampled kernel weights.
The convergence curve is thus the current maximum for each target.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">current_max</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">maximum</span><span class="o">.</span><span class="n">accumulate</span><span class="p">(</span><span class="n">cv_scores</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">mean_current_max</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">current_max</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">x_array</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">mean_current_max</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x_array</span><span class="p">,</span> <span class="n">mean_current_max</span><span class="p">,</span> <span class="s1">&#39;-o&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="s2">&quot;on&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Number of kernel weights sampled&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;L2 negative loss (higher is better)&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Convergence curve, averaged over targets&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
<img alt="Convergence curve, averaged over targets" class="sphx-glr-single-img" src="../../_images/sphx_glr_plot_mkr_random_search_001.png" />
</div>
<div class="section" id="plot-the-optimal-alphas-selected-by-the-solver">
<h2>Plot the optimal alphas selected by the solver<a class="headerlink" href="#plot-the-optimal-alphas-selected-by-the-solver" title="Permalink to this headline">¶</a></h2>
<p>This plot is helpful to refine the alpha grid if the range is too small or
too large.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">best_alphas</span> <span class="o">=</span> <span class="mf">1.</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">deltas</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">plot_alphas_diagnostic</span><span class="p">(</span><span class="n">best_alphas</span><span class="p">,</span> <span class="n">alphas</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Best alphas selected by cross-validation&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
<img alt="Best alphas selected by cross-validation" class="sphx-glr-single-img" src="../../_images/sphx_glr_plot_mkr_random_search_002.png" />
</div>
<div class="section" id="compute-the-predictions-on-the-test-set">
<h2>Compute the predictions on the test set<a class="headerlink" href="#compute-the-predictions-on-the-test-set" title="Permalink to this headline">¶</a></h2>
<p>(requires the dual weights)</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">split</span> <span class="o">=</span> <span class="kc">False</span>
<span class="n">scores</span> <span class="o">=</span> <span class="n">predict_and_score_weighted_kernel_ridge</span><span class="p">(</span>
    <span class="n">Ks_test</span><span class="p">,</span> <span class="n">dual_weights</span><span class="p">,</span> <span class="n">deltas</span><span class="p">,</span> <span class="n">Y_test</span><span class="p">,</span> <span class="n">split</span><span class="o">=</span><span class="n">split</span><span class="p">,</span>
    <span class="n">n_targets_batch</span><span class="o">=</span><span class="n">n_targets_batch</span><span class="p">,</span> <span class="n">score_func</span><span class="o">=</span><span class="n">r2_score_split</span><span class="p">)</span>
<span class="n">scores</span> <span class="o">=</span> <span class="n">backend</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">(</span><span class="n">scores</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">scores</span><span class="p">,</span> <span class="mi">50</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="sa">r</span><span class="s2">&quot;$R^2$ generalization score&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Histogram over targets&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
<img alt="Histogram over targets" class="sphx-glr-single-img" src="../../_images/sphx_glr_plot_mkr_random_search_003.png" />
</div>
<div class="section" id="compute-the-split-predictions-on-the-test-set">
<h2>Compute the split predictions on the test set<a class="headerlink" href="#compute-the-split-predictions-on-the-test-set" title="Permalink to this headline">¶</a></h2>
<p>(requires the dual weights)</p>
<p>Here we apply the dual weights on each kernel separately
(<code class="docutils literal notranslate"><span class="pre">exp(deltas[i])</span> <span class="pre">*</span> <span class="pre">kernel[i]</span></code>), and we compute the R<sup>2</sup> scores
(corrected for correlations) of each prediction.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">split</span> <span class="o">=</span> <span class="kc">True</span>
<span class="n">scores</span> <span class="o">=</span> <span class="n">predict_and_score_weighted_kernel_ridge</span><span class="p">(</span>
    <span class="n">Ks_test</span><span class="p">,</span> <span class="n">dual_weights</span><span class="p">,</span> <span class="n">deltas</span><span class="p">,</span> <span class="n">Y_test</span><span class="p">,</span> <span class="n">split</span><span class="o">=</span><span class="n">split</span><span class="p">,</span>
    <span class="n">n_targets_batch</span><span class="o">=</span><span class="n">n_targets_batch</span><span class="p">,</span> <span class="n">score_func</span><span class="o">=</span><span class="n">r2_score_split</span><span class="p">)</span>
<span class="n">scores</span> <span class="o">=</span> <span class="n">backend</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">(</span><span class="n">scores</span><span class="p">)</span>

<span class="n">bins</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="n">scores</span><span class="o">.</span><span class="n">min</span><span class="p">(),</span> <span class="n">scores</span><span class="o">.</span><span class="n">max</span><span class="p">(),</span> <span class="mi">50</span><span class="p">)</span>
<span class="k">for</span> <span class="n">score</span> <span class="ow">in</span> <span class="n">scores</span><span class="p">:</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">score</span><span class="p">,</span> <span class="n">bins</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="sa">r</span><span class="s2">&quot;Histogram of $R^2$ generalization score split between kernels&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">([</span><span class="s2">&quot;kernel </span><span class="si">%d</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="n">kk</span> <span class="k">for</span> <span class="n">kk</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">scores</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
<img alt="Histogram of $R^2$ generalization score split between kernels" class="sphx-glr-single-img" src="../../_images/sphx_glr_plot_mkr_random_search_004.png" />
<p class="sphx-glr-timing"><strong>Total running time of the script:</strong> ( 0 minutes  31.055 seconds)</p>
<div class="sphx-glr-footer class sphx-glr-footer-example docutils container" id="sphx-glr-download-auto-examples-multiple-kernel-ridge-plot-mkr-random-search-py">
<div class="sphx-glr-download sphx-glr-download-python docutils container">
<p><a class="reference download internal" download="" href="../../_downloads/b645740485a1b96ce757d668d384e15f/plot_mkr_random_search.py"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Python</span> <span class="pre">source</span> <span class="pre">code:</span> <span class="pre">plot_mkr_random_search.py</span></code></a></p>
</div>
<div class="sphx-glr-download sphx-glr-download-jupyter docutils container">
<p><a class="reference download internal" download="" href="../../_downloads/6f13151fd64e93d77ccfc70d86499686/plot_mkr_random_search.ipynb"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Jupyter</span> <span class="pre">notebook:</span> <span class="pre">plot_mkr_random_search.ipynb</span></code></a></p>
</div>
</div>
<p class="sphx-glr-signature"><a class="reference external" href="https://sphinx-gallery.github.io">Gallery generated by Sphinx-Gallery</a></p>
</div>
</div>


          </div>
          
        </div>
      </div>
    <div class="clearer"></div>
  </div>
    <div class="footer">
      &copy;2020, Gallant lab.
      
      |
      Powered by <a href="http://sphinx-doc.org/">Sphinx 4.1.2</a>
      &amp; <a href="https://github.com/bitprophet/alabaster">Alabaster 0.7.12</a>
      
      |
      <a href="../../_sources/_auto_examples/multiple_kernel_ridge/plot_mkr_random_search.rst.txt"
          rel="nofollow">Page source</a>
    </div>

    

    
  </body>
</html>