
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>Multiple-kernel ridge with scikit-learn API &#8212; Himalaya 0.3.5 documentation</title>
    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/alabaster.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sg_gallery.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sg_gallery-binder.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sg_gallery-dataframe.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sg_gallery-rendered-html.css" />
    <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
    <script src="../../_static/jquery.js"></script>
    <script src="../../_static/underscore.js"></script>
    <script src="../../_static/doctools.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="Multiple-kernel ridge solvers" href="plot_mkr_2_solvers.html" />
    <link rel="prev" title="Multiple-kernel ridge" href="plot_mkr_0_random_search.html" />
   
  <link rel="stylesheet" href="../../_static/custom.css" type="text/css" />
  
  
  <meta name="viewport" content="width=device-width, initial-scale=0.9, maximum-scale=0.9" />

  </head><body>
  <div class="document">
    
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
<p class="logo">
  <a href="../../index.html">
    <img class="logo" src="../../_static/logo.svg" alt="Logo"/>
    
  </a>
</p>






<p>
<iframe src="https://ghbtns.com/github-btn.html?user=gallantlab&repo=himalaya&type=star&count=true&size=large&v=2"
  allowtransparency="true" frameborder="0" scrolling="0" width="200px" height="35px"></iframe>
</p>





<div class="relations">
<h3>Related Topics</h3>
<ul>
  <li><a href="../../index.html">Documentation overview</a><ul>
  <li><a href="../index.html">Gallery of examples</a><ul>
      <li>Previous: <a href="plot_mkr_0_random_search.html" title="previous chapter">Multiple-kernel ridge</a></li>
      <li>Next: <a href="plot_mkr_2_solvers.html" title="next chapter">Multiple-kernel ridge solvers</a></li>
  </ul></li>
  </ul></li>
</ul>
</div><h3>Navigation</h3>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../getting_started.html">Getting started</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../models.html">Model descriptions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../troubleshooting.html">Troubleshooting</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../api.html">API Documentation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../changelog.html">Changelog</a></li>
</ul>
<ul class="current">
<li class="toctree-l1 current"><a class="reference internal" href="../index.html">Gallery of examples</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="../index.html#kernel-ridge">Kernel ridge</a></li>
<li class="toctree-l2 current"><a class="reference internal" href="../index.html#multiple-kernel-ridge">Multiple-kernel ridge</a></li>
</ul>
</li>
</ul>


<div id="searchbox" style="display: none" role="search">
  <h3 id="searchlabel">Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="../../search.html" method="get">
      <input type="text" name="q" aria-labelledby="searchlabel" autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false"/>
      <input type="submit" value="Go" />
    </form>
    </div>
</div>
<script>$('#searchbox').show(0);</script>
        </div>
      </div>
      <div class="documentwrapper">
        <div class="bodywrapper">
          

          <div class="body" role="main">
            
  <div class="sphx-glr-download-link-note admonition note">
<p class="admonition-title">Note</p>
<p>Click <a class="reference internal" href="#sphx-glr-download-auto-examples-multiple-kernel-ridge-plot-mkr-1-sklearn-api-py"><span class="std std-ref">here</span></a>
to download the full example code</p>
</div>
<section class="sphx-glr-example-title" id="multiple-kernel-ridge-with-scikit-learn-api">
<span id="sphx-glr-auto-examples-multiple-kernel-ridge-plot-mkr-1-sklearn-api-py"></span><h1>Multiple-kernel ridge with scikit-learn API<a class="headerlink" href="#multiple-kernel-ridge-with-scikit-learn-api" title="Permalink to this headline">¶</a></h1>
<p>This example demonstrates how to solve multiple kernel ridge regression, using
scikit-learn API.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>

<span class="kn">from</span> <span class="nn">himalaya.backend</span> <span class="kn">import</span> <span class="n">set_backend</span>
<span class="kn">from</span> <span class="nn">himalaya.kernel_ridge</span> <span class="kn">import</span> <span class="n">KernelRidgeCV</span>
<span class="kn">from</span> <span class="nn">himalaya.kernel_ridge</span> <span class="kn">import</span> <span class="n">MultipleKernelRidgeCV</span>
<span class="kn">from</span> <span class="nn">himalaya.kernel_ridge</span> <span class="kn">import</span> <span class="n">Kernelizer</span>
<span class="kn">from</span> <span class="nn">himalaya.kernel_ridge</span> <span class="kn">import</span> <span class="n">ColumnKernelizer</span>
<span class="kn">from</span> <span class="nn">himalaya.utils</span> <span class="kn">import</span> <span class="n">generate_multikernel_dataset</span>

<span class="kn">from</span> <span class="nn">sklearn.pipeline</span> <span class="kn">import</span> <span class="n">make_pipeline</span>
</pre></div>
</div>
<p>In this example, we use the <code class="docutils literal notranslate"><span class="pre">torch_cuda</span></code> backend.</p>
<p>Torch can perform computations both on CPU and GPU. To use CPU, use the
“torch” backend, to use GPU, use the “torch_cuda” backend.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">backend</span> <span class="o">=</span> <span class="n">set_backend</span><span class="p">(</span><span class="s2">&quot;torch_cuda&quot;</span><span class="p">,</span> <span class="n">on_error</span><span class="o">=</span><span class="s2">&quot;warn&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>/home/runner/work/himalaya/himalaya/himalaya/backend/_utils.py:56: UserWarning: Setting backend to torch_cuda failed: PyTorch with CUDA is not available..Falling back to numpy backend.
  warnings.warn(f&quot;Setting backend to {backend} failed: {str(error)}.&quot;
</pre></div>
</div>
<section id="generate-a-random-dataset">
<h2>Generate a random dataset<a class="headerlink" href="#generate-a-random-dataset" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p>X_train : array of shape (n_samples_train, n_features)</p></li>
<li><p>X_test : array of shape (n_samples_test, n_features)</p></li>
<li><p>Y_train : array of shape (n_samples_train, n_targets)</p></li>
<li><p>Y_test : array of shape (n_samples_test, n_targets)</p></li>
</ul>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">Y_train</span><span class="p">,</span> <span class="n">Y_test</span><span class="p">,</span> <span class="n">kernel_weights</span><span class="p">,</span>
 <span class="n">n_features_list</span><span class="p">)</span> <span class="o">=</span> <span class="n">generate_multikernel_dataset</span><span class="p">(</span><span class="n">n_kernels</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">n_targets</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span>
                                                 <span class="n">n_samples_train</span><span class="o">=</span><span class="mi">600</span><span class="p">,</span>
                                                 <span class="n">n_samples_test</span><span class="o">=</span><span class="mi">300</span><span class="p">,</span>
                                                 <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>

<span class="n">feature_names</span> <span class="o">=</span> <span class="p">[</span><span class="sa">f</span><span class="s2">&quot;Feature space </span><span class="si">{</span><span class="n">ii</span><span class="si">}</span><span class="s2">&quot;</span> <span class="k">for</span> <span class="n">ii</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">n_features_list</span><span class="p">))]</span>
</pre></div>
</div>
<p>We could precompute the kernels by hand on <code class="docutils literal notranslate"><span class="pre">Xs_train</span></code>, as done in
<code class="docutils literal notranslate"><span class="pre">plot_mkr_random_search.py</span></code>. Instead, here we use the <code class="docutils literal notranslate"><span class="pre">ColumnKernelizer</span></code>
to make a <code class="docutils literal notranslate"><span class="pre">scikit-learn</span></code> <code class="docutils literal notranslate"><span class="pre">Pipeline</span></code>.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># Find the start and end of each feature space X in Xs</span>
<span class="n">start_and_end</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">([[</span><span class="mi">0</span><span class="p">],</span> <span class="n">np</span><span class="o">.</span><span class="n">cumsum</span><span class="p">(</span><span class="n">n_features_list</span><span class="p">)])</span>
<span class="n">slices</span> <span class="o">=</span> <span class="p">[</span>
    <span class="nb">slice</span><span class="p">(</span><span class="n">start</span><span class="p">,</span> <span class="n">end</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">start</span><span class="p">,</span> <span class="n">end</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">start_and_end</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">start_and_end</span><span class="p">[</span><span class="mi">1</span><span class="p">:])</span>
<span class="p">]</span>
</pre></div>
</div>
<p>Create a different <code class="docutils literal notranslate"><span class="pre">Kernelizer</span></code> for each feature space. Here we use a
linear kernel for all feature spaces, but <code class="docutils literal notranslate"><span class="pre">ColumnKernelizer</span></code> accepts any
<code class="docutils literal notranslate"><span class="pre">Kernelizer</span></code>, or <code class="docutils literal notranslate"><span class="pre">scikit-learn</span></code> <code class="docutils literal notranslate"><span class="pre">Pipeline</span></code> ending with a
<code class="docutils literal notranslate"><span class="pre">Kernelizer</span></code>.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">kernelizers</span> <span class="o">=</span> <span class="p">[(</span><span class="n">name</span><span class="p">,</span> <span class="n">Kernelizer</span><span class="p">(),</span> <span class="n">slice_</span><span class="p">)</span>
               <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">slice_</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">feature_names</span><span class="p">,</span> <span class="n">slices</span><span class="p">)]</span>
<span class="n">column_kernelizer</span> <span class="o">=</span> <span class="n">ColumnKernelizer</span><span class="p">(</span><span class="n">kernelizers</span><span class="p">)</span>

<span class="c1"># Note that ``ColumnKernelizer`` has a parameter ``n_jobs`` to parallelize each</span>
<span class="c1"># kernelizer, yet such parallelism does not work with GPU arrays.</span>
</pre></div>
</div>
</section>
<section id="define-the-model">
<h2>Define the model<a class="headerlink" href="#define-the-model" title="Permalink to this headline">¶</a></h2>
<p>The class takes a number of common parameters during initialization, such as
<cite>kernels</cite> or <cite>solver</cite>. Since the solver parameters might be different
depending on the solver, they can be passed in the <cite>solver_params</cite> parameter.</p>
<p>Here we use the “random_search” solver.
We can check its specific parameters in the function docstring:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">solver_function</span> <span class="o">=</span> <span class="n">MultipleKernelRidgeCV</span><span class="o">.</span><span class="n">ALL_SOLVERS</span><span class="p">[</span><span class="s2">&quot;random_search&quot;</span><span class="p">]</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Docstring of the function </span><span class="si">%s</span><span class="s2">:&quot;</span> <span class="o">%</span> <span class="n">solver_function</span><span class="o">.</span><span class="vm">__name__</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">solver_function</span><span class="o">.</span><span class="vm">__doc__</span><span class="p">)</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>Docstring of the function solve_multiple_kernel_ridge_random_search:
Solve multiple kernel ridge regression using random search.

    Parameters
    ----------
    Ks : array of shape (n_kernels, n_samples, n_samples)
        Input kernels.
    Y : array of shape (n_samples, n_targets)
        Target data.
    n_iter : int, or array of shape (n_iter, n_kernels)
        Number of kernel weights combination to search.
        If an array is given, the solver uses it as the list of kernel weights
        to try, instead of sampling from a Dirichlet distribution.
    concentration : float, or list of float
        Concentration parameters of the Dirichlet distribution.
        If a list, iteratively cycle through the list.
        Not used if n_iter is an array.
    alphas : float or array of shape (n_alphas, )
        Range of ridge regularization parameter.
    score_func : callable
        Function used to compute the score of predictions versus Y.
    cv : int or scikit-learn splitter
        Cross-validation splitter. If an int, KFold is used.
    fit_intercept : boolean
        Whether to fit an intercept. If False, Ks should be centered
        (see KernelCenterer), and Y must be zero-mean over samples.
        Only available if return_weights == &#39;dual&#39;.
    return_weights : None, &#39;primal&#39;, or &#39;dual&#39;
        Whether to refit on the entire dataset and return the weights.
    Xs : array of shape (n_kernels, n_samples, n_features) or None
        Necessary if return_weights == &#39;primal&#39;.
    local_alpha : bool
        If True, alphas are selected per target, else shared over all targets.
    jitter_alphas : bool
        If True, alphas range is slightly jittered for each gamma.
    random_state : int, or None
        Random generator seed. Use an int for deterministic search.
    n_targets_batch : int or None
        Size of the batch for over targets during cross-validation.
        Used for memory reasons. If None, uses all n_targets at once.
    n_targets_batch_refit : int or None
        Size of the batch for over targets during refit.
        Used for memory reasons. If None, uses all n_targets at once.
    n_alphas_batch : int or None
        Size of the batch for over alphas. Used for memory reasons.
        If None, uses all n_alphas at once.
    progress_bar : bool
        If True, display a progress bar over gammas.
    Ks_in_cpu : bool
        If True, keep Ks in CPU memory to limit GPU memory (slower).
        This feature is not available through the scikit-learn API.
    conservative : bool
        If True, when selecting the hyperparameter alpha, take the largest one
        that is less than one standard deviation away from the best.
        If False, take the best.
    Y_in_cpu : bool
        If True, keep the target values ``Y`` in CPU memory (slower).
    diagonalize_method : str in {&quot;eigh&quot;, &quot;svd&quot;}
        Method used to diagonalize the kernel.
    return_alphas : bool
        If True, return the best alpha value for each target.

    Returns
    -------
    deltas : array of shape (n_kernels, n_targets)
        Best log kernel weights for each target.
    refit_weights : array or None
        Refit regression weights on the entire dataset, using selected best
        hyperparameters. Refit weights are always stored on CPU memory.
        If return_weights == &#39;primal&#39;, shape is (n_features, n_targets),
        if return_weights == &#39;dual&#39;, shape is (n_samples, n_targets),
        else, None.
    cv_scores : array of shape (n_iter, n_targets)
        Cross-validation scores per iteration, averaged over splits, for the
        best alpha. Cross-validation scores will always be on CPU memory.
    best_alphas : array of shape (n_targets, )
        Best alpha value per target. Only returned if return_alphas is True.
    intercept : array of shape (n_targets,)
        Intercept. Only returned when fit_intercept is True.
</pre></div>
</div>
<p>We use 100 iterations to have a reasonably fast example (~40 sec).
To have a better convergence, we probably need more iterations.
Note that there is currently no stopping criterion in this method.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">n_iter</span> <span class="o">=</span> <span class="mi">100</span>
</pre></div>
</div>
<p>Grid of regularization parameters.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">alphas</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">logspace</span><span class="p">(</span><span class="o">-</span><span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">41</span><span class="p">)</span>
</pre></div>
</div>
<p>Batch parameters are used to reduce the necessary GPU memory. A larger value
will be a bit faster, but the solver might crash if it runs out of memory.
Optimal values depend on the size of your dataset.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">n_targets_batch</span> <span class="o">=</span> <span class="mi">1000</span>
<span class="n">n_alphas_batch</span> <span class="o">=</span> <span class="mi">20</span>
<span class="n">n_targets_batch_refit</span> <span class="o">=</span> <span class="mi">200</span>

<span class="n">solver_params</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="n">n_iter</span><span class="o">=</span><span class="n">n_iter</span><span class="p">,</span> <span class="n">alphas</span><span class="o">=</span><span class="n">alphas</span><span class="p">,</span>
                     <span class="n">n_targets_batch</span><span class="o">=</span><span class="n">n_targets_batch</span><span class="p">,</span>
                     <span class="n">n_alphas_batch</span><span class="o">=</span><span class="n">n_alphas_batch</span><span class="p">,</span>
                     <span class="n">n_targets_batch_refit</span><span class="o">=</span><span class="n">n_targets_batch_refit</span><span class="p">,</span>
                     <span class="n">jitter_alphas</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">MultipleKernelRidgeCV</span><span class="p">(</span><span class="n">kernels</span><span class="o">=</span><span class="s2">&quot;precomputed&quot;</span><span class="p">,</span> <span class="n">solver</span><span class="o">=</span><span class="s2">&quot;random_search&quot;</span><span class="p">,</span>
                              <span class="n">solver_params</span><span class="o">=</span><span class="n">solver_params</span><span class="p">)</span>
</pre></div>
</div>
<p>Define and fit the pipeline</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">pipe</span> <span class="o">=</span> <span class="n">make_pipeline</span><span class="p">(</span><span class="n">column_kernelizer</span><span class="p">,</span> <span class="n">model</span><span class="p">)</span>
<span class="n">pipe</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">Y_train</span><span class="p">)</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>[                                        ] 0% | 0.00 sec | 100 random sampling with cv |
[                                        ] 1% | 0.68 sec | 100 random sampling with cv |
[                                        ] 2% | 1.31 sec | 100 random sampling with cv |
[.                                       ] 3% | 1.80 sec | 100 random sampling with cv |
[.                                       ] 4% | 2.39 sec | 100 random sampling with cv |
[..                                      ] 5% | 2.94 sec | 100 random sampling with cv |
[..                                      ] 6% | 3.52 sec | 100 random sampling with cv |
[..                                      ] 7% | 4.02 sec | 100 random sampling with cv |
[...                                     ] 8% | 4.60 sec | 100 random sampling with cv |
[...                                     ] 9% | 5.18 sec | 100 random sampling with cv |
[....                                    ] 10% | 5.65 sec | 100 random sampling with cv |
[....                                    ] 11% | 6.09 sec | 100 random sampling with cv |
[....                                    ] 12% | 6.75 sec | 100 random sampling with cv |
[.....                                   ] 13% | 7.24 sec | 100 random sampling with cv |
[.....                                   ] 14% | 7.83 sec | 100 random sampling with cv |
[......                                  ] 15% | 8.38 sec | 100 random sampling with cv |
[......                                  ] 16% | 8.90 sec | 100 random sampling with cv |
[......                                  ] 17% | 9.37 sec | 100 random sampling with cv |
[.......                                 ] 18% | 9.94 sec | 100 random sampling with cv |
[.......                                 ] 19% | 10.43 sec | 100 random sampling with cv |
[........                                ] 20% | 11.01 sec | 100 random sampling with cv |
[........                                ] 21% | 11.49 sec | 100 random sampling with cv |
[........                                ] 22% | 12.14 sec | 100 random sampling with cv |
[.........                               ] 23% | 12.61 sec | 100 random sampling with cv |
[.........                               ] 24% | 13.20 sec | 100 random sampling with cv |
[..........                              ] 25% | 13.68 sec | 100 random sampling with cv |
[..........                              ] 26% | 14.19 sec | 100 random sampling with cv |
[..........                              ] 27% | 14.65 sec | 100 random sampling with cv |
[...........                             ] 28% | 15.19 sec | 100 random sampling with cv |
[...........                             ] 29% | 15.64 sec | 100 random sampling with cv |
[............                            ] 30% | 16.08 sec | 100 random sampling with cv |
[............                            ] 31% | 16.59 sec | 100 random sampling with cv |
[............                            ] 32% | 17.12 sec | 100 random sampling with cv |
[.............                           ] 33% | 17.69 sec | 100 random sampling with cv |
[.............                           ] 34% | 18.25 sec | 100 random sampling with cv |
[..............                          ] 35% | 18.72 sec | 100 random sampling with cv |
[..............                          ] 36% | 19.26 sec | 100 random sampling with cv |
[..............                          ] 37% | 19.71 sec | 100 random sampling with cv |
[...............                         ] 38% | 20.32 sec | 100 random sampling with cv |
[...............                         ] 39% | 20.97 sec | 100 random sampling with cv |
[................                        ] 40% | 21.43 sec | 100 random sampling with cv |
[................                        ] 41% | 21.92 sec | 100 random sampling with cv |
[................                        ] 42% | 22.45 sec | 100 random sampling with cv |
[.................                       ] 43% | 22.90 sec | 100 random sampling with cv |
[.................                       ] 44% | 23.36 sec | 100 random sampling with cv |
[..................                      ] 45% | 23.92 sec | 100 random sampling with cv |
[..................                      ] 46% | 24.50 sec | 100 random sampling with cv |
[..................                      ] 47% | 25.00 sec | 100 random sampling with cv |
[...................                     ] 48% | 25.46 sec | 100 random sampling with cv |
[...................                     ] 49% | 25.86 sec | 100 random sampling with cv |
[....................                    ] 50% | 26.34 sec | 100 random sampling with cv |
[....................                    ] 51% | 26.81 sec | 100 random sampling with cv |
[....................                    ] 52% | 27.29 sec | 100 random sampling with cv |
[.....................                   ] 53% | 27.80 sec | 100 random sampling with cv |
[.....................                   ] 54% | 28.25 sec | 100 random sampling with cv |
[......................                  ] 55% | 28.79 sec | 100 random sampling with cv |
[......................                  ] 56% | 29.23 sec | 100 random sampling with cv |
[......................                  ] 57% | 29.63 sec | 100 random sampling with cv |
[.......................                 ] 58% | 30.19 sec | 100 random sampling with cv |
[.......................                 ] 59% | 30.60 sec | 100 random sampling with cv |
[........................                ] 60% | 31.04 sec | 100 random sampling with cv |
[........................                ] 61% | 31.45 sec | 100 random sampling with cv |
[........................                ] 62% | 31.97 sec | 100 random sampling with cv |
[.........................               ] 63% | 32.34 sec | 100 random sampling with cv |
[.........................               ] 64% | 32.82 sec | 100 random sampling with cv |
[..........................              ] 65% | 33.37 sec | 100 random sampling with cv |
[..........................              ] 66% | 33.81 sec | 100 random sampling with cv |
[..........................              ] 67% | 34.39 sec | 100 random sampling with cv |
[...........................             ] 68% | 34.87 sec | 100 random sampling with cv |
[...........................             ] 69% | 35.29 sec | 100 random sampling with cv |
[............................            ] 70% | 35.75 sec | 100 random sampling with cv |
[............................            ] 71% | 36.32 sec | 100 random sampling with cv |
[............................            ] 72% | 36.77 sec | 100 random sampling with cv |
[.............................           ] 73% | 37.21 sec | 100 random sampling with cv |
[.............................           ] 74% | 37.69 sec | 100 random sampling with cv |
[..............................          ] 75% | 38.20 sec | 100 random sampling with cv |
[..............................          ] 76% | 38.77 sec | 100 random sampling with cv |
[..............................          ] 77% | 39.33 sec | 100 random sampling with cv |
[...............................         ] 78% | 39.92 sec | 100 random sampling with cv |
[...............................         ] 79% | 40.63 sec | 100 random sampling with cv |
[................................        ] 80% | 41.05 sec | 100 random sampling with cv |
[................................        ] 81% | 41.51 sec | 100 random sampling with cv |
[................................        ] 82% | 42.04 sec | 100 random sampling with cv |
[.................................       ] 83% | 42.52 sec | 100 random sampling with cv |
[.................................       ] 84% | 43.19 sec | 100 random sampling with cv |
[..................................      ] 85% | 43.71 sec | 100 random sampling with cv |
[..................................      ] 86% | 44.21 sec | 100 random sampling with cv |
[..................................      ] 87% | 44.69 sec | 100 random sampling with cv |
[...................................     ] 88% | 45.19 sec | 100 random sampling with cv |
[...................................     ] 89% | 45.60 sec | 100 random sampling with cv |
[....................................    ] 90% | 46.24 sec | 100 random sampling with cv |
[....................................    ] 91% | 46.86 sec | 100 random sampling with cv |
[....................................    ] 92% | 47.45 sec | 100 random sampling with cv |
[.....................................   ] 93% | 47.99 sec | 100 random sampling with cv |
[.....................................   ] 94% | 48.58 sec | 100 random sampling with cv |
[......................................  ] 95% | 49.10 sec | 100 random sampling with cv |
[......................................  ] 96% | 49.64 sec | 100 random sampling with cv |
[......................................  ] 97% | 50.22 sec | 100 random sampling with cv |
[....................................... ] 98% | 50.84 sec | 100 random sampling with cv |
[....................................... ] 99% | 51.40 sec | 100 random sampling with cv |
[........................................] 100% | 51.89 sec | 100 random sampling with cv |

Pipeline(steps=[(&#39;columnkernelizer&#39;,
                 ColumnKernelizer(transformers=[(&#39;Feature space 0&#39;,
                                                 Kernelizer(),
                                                 slice(0, 1000, None)),
                                                (&#39;Feature space 1&#39;,
                                                 Kernelizer(),
                                                 slice(1000, 2000, None)),
                                                (&#39;Feature space 2&#39;,
                                                 Kernelizer(),
                                                 slice(2000, 3000, None))])),
                (&#39;multiplekernelridgecv&#39;,
                 MultipleKernelRidgeCV(kernels=&#39;precomputed&#39;,
                                       solver_params={&#39;alphas&#39;: array([1.00000000e-10, 3.1622776...
       1.00000000e+02, 3.16227766e+02, 1.00000000e+03, 3.16227766e+03,
       1.00000000e+04, 3.16227766e+04, 1.00000000e+05, 3.16227766e+05,
       1.00000000e+06, 3.16227766e+06, 1.00000000e+07, 3.16227766e+07,
       1.00000000e+08, 3.16227766e+08, 1.00000000e+09, 3.16227766e+09,
       1.00000000e+10]),
                                                      &#39;jitter_alphas&#39;: True,
                                                      &#39;n_alphas_batch&#39;: 20,
                                                      &#39;n_iter&#39;: 100,
                                                      &#39;n_targets_batch&#39;: 1000,
                                                      &#39;n_targets_batch_refit&#39;: 200}))])
</pre></div>
</div>
</section>
<section id="plot-the-convergence-curve">
<h2>Plot the convergence curve<a class="headerlink" href="#plot-the-convergence-curve" title="Permalink to this headline">¶</a></h2>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># ``cv_scores`` gives the scores for each sampled kernel weights.</span>
<span class="c1"># The convergence curve is thus the current maximum for each target.</span>
<span class="n">cv_scores</span> <span class="o">=</span> <span class="n">backend</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">(</span><span class="n">pipe</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">cv_scores_</span><span class="p">)</span>
<span class="n">current_max</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">maximum</span><span class="o">.</span><span class="n">accumulate</span><span class="p">(</span><span class="n">cv_scores</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">mean_current_max</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">current_max</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="n">x_array</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">mean_current_max</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x_array</span><span class="p">,</span> <span class="n">mean_current_max</span><span class="p">,</span> <span class="s1">&#39;-o&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="s2">&quot;on&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Number of kernel weights sampled&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;L2 negative loss (higher is better)&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Convergence curve, averaged over targets&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
<img src="../../_images/sphx_glr_plot_mkr_1_sklearn_api_001.png" srcset="../../_images/sphx_glr_plot_mkr_1_sklearn_api_001.png" alt="Convergence curve, averaged over targets" class = "sphx-glr-single-img"/></section>
<section id="compare-to-kernelridgecv">
<h2>Compare to <code class="docutils literal notranslate"><span class="pre">KernelRidgeCV</span></code><a class="headerlink" href="#compare-to-kernelridgecv" title="Permalink to this headline">¶</a></h2>
<p>Compare to a baseline <code class="docutils literal notranslate"><span class="pre">KernelRidgeCV</span></code> model with all the concatenated
features. Comparison is performed using the prediction scores on the test
set.</p>
<p>Fit the baseline model <code class="docutils literal notranslate"><span class="pre">KernelRidgeCV</span></code></p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">baseline</span> <span class="o">=</span> <span class="n">KernelRidgeCV</span><span class="p">(</span><span class="n">kernel</span><span class="o">=</span><span class="s2">&quot;linear&quot;</span><span class="p">,</span> <span class="n">alphas</span><span class="o">=</span><span class="n">alphas</span><span class="p">)</span>
<span class="n">baseline</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">Y_train</span><span class="p">)</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>KernelRidgeCV(alphas=array([1.00000000e-10, 3.16227766e-10, 1.00000000e-09, 3.16227766e-09,
       1.00000000e-08, 3.16227766e-08, 1.00000000e-07, 3.16227766e-07,
       1.00000000e-06, 3.16227766e-06, 1.00000000e-05, 3.16227766e-05,
       1.00000000e-04, 3.16227766e-04, 1.00000000e-03, 3.16227766e-03,
       1.00000000e-02, 3.16227766e-02, 1.00000000e-01, 3.16227766e-01,
       1.00000000e+00, 3.16227766e+00, 1.00000000e+01, 3.16227766e+01,
       1.00000000e+02, 3.16227766e+02, 1.00000000e+03, 3.16227766e+03,
       1.00000000e+04, 3.16227766e+04, 1.00000000e+05, 3.16227766e+05,
       1.00000000e+06, 3.16227766e+06, 1.00000000e+07, 3.16227766e+07,
       1.00000000e+08, 3.16227766e+08, 1.00000000e+09, 3.16227766e+09,
       1.00000000e+10]))
</pre></div>
</div>
<p>Compute scores of both models</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">scores</span> <span class="o">=</span> <span class="n">pipe</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">Y_test</span><span class="p">)</span>
<span class="n">scores</span> <span class="o">=</span> <span class="n">backend</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">(</span><span class="n">scores</span><span class="p">)</span>

<span class="n">scores_baseline</span> <span class="o">=</span> <span class="n">baseline</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">Y_test</span><span class="p">)</span>
<span class="n">scores_baseline</span> <span class="o">=</span> <span class="n">backend</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">(</span><span class="n">scores_baseline</span><span class="p">)</span>
</pre></div>
</div>
<p>Plot histograms</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">bins</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nb">max</span><span class="p">(</span><span class="n">scores_baseline</span><span class="o">.</span><span class="n">max</span><span class="p">(),</span> <span class="n">scores</span><span class="o">.</span><span class="n">max</span><span class="p">()),</span> <span class="mi">50</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">scores_baseline</span><span class="p">,</span> <span class="n">bins</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.7</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;KernelRidgeCV&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">scores</span><span class="p">,</span> <span class="n">bins</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.7</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;MultipleKernelRidgeCV&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="sa">r</span><span class="s2">&quot;$R^2$ generalization score&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Histogram over targets&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
<img src="../../_images/sphx_glr_plot_mkr_1_sklearn_api_002.png" srcset="../../_images/sphx_glr_plot_mkr_1_sklearn_api_002.png" alt="Histogram over targets" class = "sphx-glr-single-img"/><p class="sphx-glr-timing"><strong>Total running time of the script:</strong> ( 0 minutes  53.605 seconds)</p>
<div class="sphx-glr-footer class sphx-glr-footer-example docutils container" id="sphx-glr-download-auto-examples-multiple-kernel-ridge-plot-mkr-1-sklearn-api-py">
<div class="sphx-glr-download sphx-glr-download-python docutils container">
<p><a class="reference download internal" download="" href="../../_downloads/fc308285b553b80d3c9be578d088265d/plot_mkr_1_sklearn_api.py"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Python</span> <span class="pre">source</span> <span class="pre">code:</span> <span class="pre">plot_mkr_1_sklearn_api.py</span></code></a></p>
</div>
<div class="sphx-glr-download sphx-glr-download-jupyter docutils container">
<p><a class="reference download internal" download="" href="../../_downloads/2807b30d5475271095a9dd91c0f89aa5/plot_mkr_1_sklearn_api.ipynb"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Jupyter</span> <span class="pre">notebook:</span> <span class="pre">plot_mkr_1_sklearn_api.ipynb</span></code></a></p>
</div>
</div>
<p class="sphx-glr-signature"><a class="reference external" href="https://sphinx-gallery.github.io">Gallery generated by Sphinx-Gallery</a></p>
</section>
</section>


          </div>
          
        </div>
      </div>
    <div class="clearer"></div>
  </div>
    <div class="footer">
      &copy;2020, Gallant lab.
      
      |
      Powered by <a href="http://sphinx-doc.org/">Sphinx 4.4.0</a>
      &amp; <a href="https://github.com/bitprophet/alabaster">Alabaster 0.7.12</a>
      
      |
      <a href="../../_sources/_auto_examples/multiple_kernel_ridge/plot_mkr_1_sklearn_api.rst.txt"
          rel="nofollow">Page source</a>
    </div>

    

    
  </body>
</html>