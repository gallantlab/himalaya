<!DOCTYPE html>

<html lang="en" data-content_root="./">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>Troubleshooting &#8212; Himalaya 0.4.9 documentation</title>
    <link rel="stylesheet" type="text/css" href="_static/pygments.css?v=03e43079" />
    <link rel="stylesheet" type="text/css" href="_static/alabaster.css?v=e9c93658" />
    <link rel="stylesheet" type="text/css" href="_static/sg_gallery.css?v=d2d258e8" />
    <link rel="stylesheet" type="text/css" href="_static/sg_gallery-binder.css?v=f4aeca0c" />
    <link rel="stylesheet" type="text/css" href="_static/sg_gallery-dataframe.css?v=2082cf3c" />
    <link rel="stylesheet" type="text/css" href="_static/sg_gallery-rendered-html.css?v=1277b6f3" />
    <script src="_static/documentation_options.js?v=ebe9904d"></script>
    <script src="_static/doctools.js?v=9a2dae69"></script>
    <script src="_static/sphinx_highlight.js?v=dc90522c"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Gallery of examples" href="_auto_examples/index.html" />
    <link rel="prev" title="Model flowchart" href="flowchart.html" />
   
  <link rel="stylesheet" href="_static/custom.css" type="text/css" />
  

  
  

  </head><body>
  <div class="document">
    
      <div class="sphinxsidebar" role="navigation" aria-label="Main">
        <div class="sphinxsidebarwrapper">
<p class="logo">
  <a href="index.html">
    <img class="logo" src="_static/logo.svg" alt="Logo" />
    
    <h1 class="logo logo-name">himalaya</h1>
    
  </a>
</p>






<p>
<iframe src="https://ghbtns.com/github-btn.html?user=gallantlab&repo=himalaya&type=star&count=true&size=large&v=2"
  allowtransparency="true" frameborder="0" scrolling="0" width="200px" height="35px"></iframe>
</p>





<div class="relations">
<h3>Related Topics</h3>
<ul>
  <li><a href="index.html">Documentation overview</a><ul>
      <li>Previous: <a href="flowchart.html" title="previous chapter">Model flowchart</a></li>
      <li>Next: <a href="_auto_examples/index.html" title="next chapter">Gallery of examples</a></li>
  </ul></li>
</ul>
</div><h3>Navigation</h3>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="getting_started.html">Getting started</a></li>
<li class="toctree-l1"><a class="reference internal" href="models.html">Model descriptions</a></li>
<li class="toctree-l1"><a class="reference internal" href="flowchart.html">Model flowchart</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Troubleshooting</a></li>
<li class="toctree-l1"><a class="reference internal" href="_auto_examples/index.html">Gallery of examples</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="api.html">API</a></li>
<li class="toctree-l1"><a class="reference internal" href="changelog.html">Changelog</a></li>
</ul>


<search id="searchbox" style="display: none" role="search">
  <h3 id="searchlabel">Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="search.html" method="get">
      <input type="text" name="q" aria-labelledby="searchlabel" autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false"/>
      <input type="submit" value="Go" />
    </form>
    </div>
</search>
<script>document.getElementById('searchbox').style.display = "block"</script>
        </div>
      </div>
      <div class="documentwrapper">
        <div class="bodywrapper">
          

          <div class="body" role="main">
            
  <section id="troubleshooting">
<h1>Troubleshooting<a class="headerlink" href="#troubleshooting" title="Link to this heading">¶</a></h1>
<p>We detail here common issues encountered with <code class="docutils literal notranslate"><span class="pre">himalaya</span></code>, and how to fix
them.</p>
<div class="toctree-wrapper compound">
</div>
<section id="cuda-out-of-memory">
<h2>CUDA out of memory<a class="headerlink" href="#cuda-out-of-memory" title="Link to this heading">¶</a></h2>
<p>The GPU memory is often smaller than the CPU memory, so it requires more
attention to avoid running out of memory. Himalaya implements a series of
options to limit the GPU memory, often at the cost of computational speed:</p>
<ul class="simple">
<li><p>Some solvers implement computations over batches, to limit the size of
intermediate arrays. See for instance <code class="docutils literal notranslate"><span class="pre">n_targets_batch</span></code>, or
<code class="docutils literal notranslate"><span class="pre">n_alphas_batch</span></code> in <a class="reference internal" href="_generated/himalaya.kernel_ridge.KernelRidgeCV.html#himalaya.kernel_ridge.KernelRidgeCV" title="himalaya.kernel_ridge.KernelRidgeCV"><code class="xref py py-class docutils literal notranslate"><span class="pre">KernelRidgeCV</span></code></a>.</p></li>
<li><p>Some solvers implement an option to keep the input kernels or the targets in
CPU memory. See for instance <code class="docutils literal notranslate"><span class="pre">Y_in_cpu</span></code> in
<a class="reference internal" href="_generated/himalaya.kernel_ridge.MultipleKernelRidgeCV.html#himalaya.kernel_ridge.MultipleKernelRidgeCV" title="himalaya.kernel_ridge.MultipleKernelRidgeCV"><code class="xref py py-class docutils literal notranslate"><span class="pre">MultipleKernelRidgeCV</span></code></a>.</p></li>
<li><p>Some estimators can also be forced to use CPU, ignoring the current backend,
using the parameter <code class="docutils literal notranslate"><span class="pre">force_cpu=True</span></code>. To limit GPU memory, some estimators
in the same pipeline can use <code class="docutils literal notranslate"><span class="pre">force_cpu=True</span></code> and others
<code class="docutils literal notranslate"><span class="pre">force_cpu=False</span></code>. In particular, it is possible to precompute kernels on
CPU, using <a class="reference internal" href="_generated/himalaya.kernel_ridge.Kernelizer.html#himalaya.kernel_ridge.Kernelizer" title="himalaya.kernel_ridge.Kernelizer"><code class="xref py py-class docutils literal notranslate"><span class="pre">Kernelizer</span></code></a> or
<a class="reference internal" href="_generated/himalaya.kernel_ridge.ColumnKernelizer.html#himalaya.kernel_ridge.ColumnKernelizer" title="himalaya.kernel_ridge.ColumnKernelizer"><code class="xref py py-class docutils literal notranslate"><span class="pre">ColumnKernelizer</span></code></a> with the parameter
<code class="docutils literal notranslate"><span class="pre">force_cpu=True</span></code> before fitting a
<a class="reference internal" href="_generated/himalaya.kernel_ridge.KernelRidgeCV.html#himalaya.kernel_ridge.KernelRidgeCV" title="himalaya.kernel_ridge.KernelRidgeCV"><code class="xref py py-class docutils literal notranslate"><span class="pre">KernelRidgeCV</span></code></a> or a
<a class="reference internal" href="_generated/himalaya.kernel_ridge.MultipleKernelRidgeCV.html#himalaya.kernel_ridge.MultipleKernelRidgeCV" title="himalaya.kernel_ridge.MultipleKernelRidgeCV"><code class="xref py py-class docutils literal notranslate"><span class="pre">MultipleKernelRidgeCV</span></code></a> on GPU.</p></li>
</ul>
<p>A CUDA out of memory issue can also arise with <code class="docutils literal notranslate"><span class="pre">pytorch</span> <span class="pre">&lt;</span> <span class="pre">1.9</span></code>, for example
with <a class="reference internal" href="_generated/himalaya.kernel_ridge.KernelRidge.html#himalaya.kernel_ridge.KernelRidge" title="himalaya.kernel_ridge.KernelRidge"><code class="xref py py-class docutils literal notranslate"><span class="pre">KernelRidge</span></code></a>, where a solver requires
ridiculously high peak memory during a broadcasting matmul operation. This
<a class="reference external" href="https://github.com/pytorch/pytorch/pull/54616">issue</a> can be fixed by
updating to <code class="docutils literal notranslate"><span class="pre">pytorch</span> <span class="pre">=</span> <span class="pre">1.9</span></code> or newer versions.</p>
</section>
<section id="slow-check-array">
<h2>Slow check_array<a class="headerlink" href="#slow-check-array" title="Link to this heading">¶</a></h2>
<p>In himalaya, the scikit-learn compatible estimators validate the input data,
checking the absence of NaN or infinite values. For large datasets, this check
can take significant computational time. To skip this check, simply call
<code class="docutils literal notranslate"><span class="pre">sklearn.set_config(assume_finite=True)</span></code> before fitting your models.</p>
</section>
<section id="eigenvalue-decomposition-error-in-kernel-ridge-solvers">
<h2>Eigenvalue decomposition error in kernel ridge solvers<a class="headerlink" href="#eigenvalue-decomposition-error-in-kernel-ridge-solvers" title="Link to this heading">¶</a></h2>
<p>When using GPU backends (e.g. <code class="docutils literal notranslate"><span class="pre">torch_cuda</span></code>) with float32 precision, the
eigenvalue decomposition (<code class="docutils literal notranslate"><span class="pre">eigh</span></code>) used internally by
<a class="reference internal" href="_generated/himalaya.kernel_ridge.KernelRidgeCV.html#himalaya.kernel_ridge.KernelRidgeCV" title="himalaya.kernel_ridge.KernelRidgeCV"><code class="xref py py-class docutils literal notranslate"><span class="pre">KernelRidgeCV</span></code></a> and
<a class="reference internal" href="_generated/himalaya.kernel_ridge.MultipleKernelRidgeCV.html#himalaya.kernel_ridge.MultipleKernelRidgeCV" title="himalaya.kernel_ridge.MultipleKernelRidgeCV"><code class="xref py py-class docutils literal notranslate"><span class="pre">MultipleKernelRidgeCV</span></code></a> solvers can fail on
ill-conditioned kernel matrices. This typically raises errors from the
underlying <code class="docutils literal notranslate"><span class="pre">eigh</span></code> routine.</p>
<p>To work around this, pass <code class="docutils literal notranslate"><span class="pre">solver_params=dict(diagonalize_method=&quot;svd&quot;)</span></code> to
use SVD instead of <code class="docutils literal notranslate"><span class="pre">eigh</span></code> for the decomposition. SVD is slower but more
numerically robust:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">KernelRidgeCV</span><span class="p">(</span><span class="n">solver_params</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span><span class="n">diagonalize_method</span><span class="o">=</span><span class="s2">&quot;svd&quot;</span><span class="p">))</span>
</pre></div>
</div>
</section>
</section>


          </div>
          
        </div>
      </div>
    <div class="clearer"></div>
  </div>
    <div class="footer">
      &#169;2023, Gallant lab.
      
      |
      Powered by <a href="https://www.sphinx-doc.org/">Sphinx 7.4.7</a>
      &amp; <a href="https://alabaster.readthedocs.io">Alabaster 0.7.16</a>
      
      |
      <a href="_sources/troubleshooting.rst.txt"
          rel="nofollow">Page source</a>
    </div>

    

    
  </body>
</html>