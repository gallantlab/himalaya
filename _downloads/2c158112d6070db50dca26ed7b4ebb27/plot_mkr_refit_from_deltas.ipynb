{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Fit a multiple-kernel ridge models from fixed hyper-parameters\nThis example demonstrates how to fit a multiple-kernel ridge model with fixed\nhyper-parameters. Here are three different usecases:\n- If the kernel weights hyper-parameters are known and identical across\n  targets, the kernels can be scaled and summed, and a simple KernelRidgeCV can\n  be used to fit the model.\n- If the kernel weights hyper-parameters are unknown and different across\n  targets, a MultipleKernelRidgeCV can be use to search the best\n  hyper-parameters per target.\n- If the kernel weights hyper-parameters are known and different across\n  targets, a WeightedKernelRidge model can be used to fit the ridge models on\n  each target independently.\n\nThis method can be used for example in the following workflow:\n- fit a MultipleKernelRidgeCV to learn the kernel weights hyper-parameter,\n- save the hyper-parameters, but not the ridge weights to save disk space,\n- fit a WeightedKernelRidge from the saved hyper-parameters, for further use of\n  the model (prediction, interpretation, etc.).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import numpy as np\n\nfrom himalaya.backend import set_backend\nfrom himalaya.kernel_ridge import WeightedKernelRidge\nfrom himalaya.kernel_ridge import Kernelizer\nfrom himalaya.kernel_ridge import ColumnKernelizer\nfrom himalaya.kernel_ridge import generate_dirichlet_samples\n\nfrom sklearn.pipeline import make_pipeline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In this example, we use the ``torch_cuda`` backend (GPU).\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "backend = set_backend(\"torch_cuda\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can display the ``scikit-learn`` pipeline with an HTML diagram.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from sklearn import set_config\nset_config(display='diagram')  # requires scikit-learn 0.23"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Generate a random dataset\n- Xs_train : list of arrays of shape (n_samples_train, n_features)\n- Xs_test : list of arrays of shape (n_samples_test, n_features)\n- Y_train : array of shape (n_samples_train, n_targets)\n- Y_test : array of shape (n_repeat, n_samples_test, n_targets)\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "n_kernels = 4\nn_targets = 500\n\n# We create a few kernel weights\nrng = np.random.RandomState(42)\nkernel_weights_true = generate_dirichlet_samples(n_targets, n_kernels,\n                                                 concentration=[.3],\n                                                 random_state=rng)\nkernel_weights_true = backend.to_numpy(kernel_weights_true)\n\n# Then, we generate a random dataset, using the arbitrary scalings.\nn_samples_train = 1000\nn_samples_test = 400\nn_features_list = np.full(n_kernels, fill_value=1000)\n\nXs_train, Xs_test = [], []\nY_train, Y_test = None, None\nfor ii in range(n_kernels):\n    n_features = n_features_list[ii]\n\n    X_train = rng.randn(n_samples_train, n_features)\n    X_test = rng.randn(n_samples_test, n_features)\n    X_train -= X_train.mean(0)\n    Xs_train.append(X_train)\n    Xs_test.append(X_test)\n\n    weights = rng.randn(n_features, n_targets) / n_features\n    weights *= kernel_weights_true[:, ii] ** 0.5\n\n    if ii == 0:\n        Y_train = X_train @ weights\n        Y_test = X_test @ weights\n    else:\n        Y_train += X_train @ weights\n        Y_test += X_test @ weights\n\nstd = Y_train.std(0)[None]\nY_train /= std\nY_test /= std\n\nnoise = 0.1\nY_train += rng.randn(n_samples_train, n_targets) * noise\nY_test += rng.randn(n_samples_test, n_targets) * noise\nY_test -= Y_test.mean(0)\nY_train -= Y_train.mean(0)\n\n# Concatenate the feature spaces.\nX_train = np.asarray(np.concatenate(Xs_train, 1), dtype=\"float32\")\nX_test = np.asarray(np.concatenate(Xs_test, 1), dtype=\"float32\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Prepare the pipeline\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Find the start and end of each feature space X in Xs\nstart_and_end = np.concatenate([[0], np.cumsum(n_features_list)])\nslices = [\n    slice(start, end)\n    for start, end in zip(start_and_end[:-1], start_and_end[1:])\n]\n\n# Create a different ``Kernelizer`` for each feature space.\nkernelizers = [(\"space %d\" % ii, Kernelizer(), slice_)\n               for ii, slice_ in enumerate(slices)]\ncolumn_kernelizer = ColumnKernelizer(kernelizers)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Define the weighted kernel ridge model\nHere we use the ground truth kernel weights for each target (deltas), but it\ncan be typically used with deltas obtained from a MultipleKernelRidgeCV fit.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "deltas = backend.log(backend.asarray(kernel_weights_true.T))\n\nmodel_1 = WeightedKernelRidge(alpha=1, deltas=deltas, kernels=\"precomputed\")\npipe_1 = make_pipeline(column_kernelizer, model_1)\n\n# Fit the model on all targets\npipe_1.fit(X_train, Y_train)\n\n# compute test score\ntest_scores_1 = pipe_1.score(X_test, Y_test)\ntest_scores_1 = backend.to_numpy(test_scores_1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can compare this model to a baseline model where the kernel weights are\nall equal and not learnt.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "model_2 = WeightedKernelRidge(alpha=1, deltas=\"zeros\", kernels=\"precomputed\")\npipe_2 = make_pipeline(column_kernelizer, model_2)\n\n# Fit the model on all targets\npipe_2.fit(X_train, Y_train)\n\n# compute test score\ntest_scores_2 = pipe_2.score(X_test, Y_test)\ntest_scores_2 = backend.to_numpy(test_scores_2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Compare the predictions on a test set\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n\nplt.figure(figsize=(4, 3))\nplt.hist(test_scores_2, np.linspace(0, 1, 30), alpha=0.7,\n         label=\"Default deltas\")\nplt.hist(test_scores_1, np.linspace(0, 1, 30), alpha=0.7,\n         label=\"Ground truth deltas\")\nplt.xlabel(\"$R^2$ generalization score\")\nplt.ylabel(\"Number of voxels\")\nplt.legend()\nplt.tight_layout()\nplt.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}