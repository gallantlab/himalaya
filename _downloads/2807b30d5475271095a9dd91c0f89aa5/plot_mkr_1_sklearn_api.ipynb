{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Multiple-kernel ridge with scikit-learn API\nThis example demonstrates how to solve multiple kernel ridge regression, using\nscikit-learn API.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import numpy as np\nimport matplotlib.pyplot as plt\n\nfrom himalaya.backend import set_backend\nfrom himalaya.kernel_ridge import KernelRidgeCV\nfrom himalaya.kernel_ridge import MultipleKernelRidgeCV\nfrom himalaya.kernel_ridge import Kernelizer\nfrom himalaya.kernel_ridge import ColumnKernelizer\nfrom himalaya.utils import generate_multikernel_dataset\n\nfrom sklearn.pipeline import make_pipeline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In this example, we use the ``torch_cuda`` backend.\n\nTorch can perform computations both on CPU and GPU. To use CPU, use the\n\"torch\" backend, to use GPU, use the \"torch_cuda\" backend.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "backend = set_backend(\"torch_cuda\", on_error=\"warn\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Generate a random dataset\n- X_train : array of shape (n_samples_train, n_features)\n- X_test : array of shape (n_samples_test, n_features)\n- Y_train : array of shape (n_samples_train, n_targets)\n- Y_test : array of shape (n_samples_test, n_targets)\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "(X_train, X_test, Y_train, Y_test, kernel_weights,\n n_features_list) = generate_multikernel_dataset(n_kernels=3, n_targets=50,\n                                                 n_samples_train=600,\n                                                 n_samples_test=300,\n                                                 random_state=42)\n\nfeature_names = [f\"Feature space {ii}\" for ii in range(len(n_features_list))]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We could precompute the kernels by hand on ``Xs_train``, as done in\n``plot_mkr_random_search.py``. Instead, here we use the ``ColumnKernelizer``\nto make a ``scikit-learn`` ``Pipeline``.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Find the start and end of each feature space X in Xs\nstart_and_end = np.concatenate([[0], np.cumsum(n_features_list)])\nslices = [\n    slice(start, end)\n    for start, end in zip(start_and_end[:-1], start_and_end[1:])\n]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Create a different ``Kernelizer`` for each feature space. Here we use a\nlinear kernel for all feature spaces, but ``ColumnKernelizer`` accepts any\n``Kernelizer``, or ``scikit-learn`` ``Pipeline`` ending with a\n``Kernelizer``.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "kernelizers = [(name, Kernelizer(), slice_)\n               for name, slice_ in zip(feature_names, slices)]\ncolumn_kernelizer = ColumnKernelizer(kernelizers)\n\n# Note that ``ColumnKernelizer`` has a parameter ``n_jobs`` to parallelize each\n# kernelizer, yet such parallelism does not work with GPU arrays."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Define the model\n\nThe class takes a number of common parameters during initialization, such as\n`kernels` or `solver`. Since the solver parameters might be different\ndepending on the solver, they can be passed in the `solver_params` parameter.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Here we use the \"random_search\" solver.\nWe can check its specific parameters in the function docstring:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "solver_function = MultipleKernelRidgeCV.ALL_SOLVERS[\"random_search\"]\nprint(\"Docstring of the function %s:\" % solver_function.__name__)\nprint(solver_function.__doc__)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We use 100 iterations to have a reasonably fast example (~40 sec).\nTo have a better convergence, we probably need more iterations.\nNote that there is currently no stopping criterion in this method.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "n_iter = 100"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Grid of regularization parameters.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "alphas = np.logspace(-10, 10, 41)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Batch parameters are used to reduce the necessary GPU memory. A larger value\nwill be a bit faster, but the solver might crash if it runs out of memory.\nOptimal values depend on the size of your dataset.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "n_targets_batch = 1000\nn_alphas_batch = 20\nn_targets_batch_refit = 200\n\nsolver_params = dict(n_iter=n_iter, alphas=alphas,\n                     n_targets_batch=n_targets_batch,\n                     n_alphas_batch=n_alphas_batch,\n                     n_targets_batch_refit=n_targets_batch_refit,\n                     jitter_alphas=True)\n\nmodel = MultipleKernelRidgeCV(kernels=\"precomputed\", solver=\"random_search\",\n                              solver_params=solver_params)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Define and fit the pipeline\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "pipe = make_pipeline(column_kernelizer, model)\npipe.fit(X_train, Y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Plot the convergence curve\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# ``cv_scores`` gives the scores for each sampled kernel weights.\n# The convergence curve is thus the current maximum for each target.\ncv_scores = backend.to_numpy(pipe[1].cv_scores_)\ncurrent_max = np.maximum.accumulate(cv_scores, axis=0)\nmean_current_max = np.mean(current_max, axis=1)\n\nx_array = np.arange(1, len(mean_current_max) + 1)\nplt.plot(x_array, mean_current_max, '-o')\nplt.grid(\"on\")\nplt.xlabel(\"Number of kernel weights sampled\")\nplt.ylabel(\"L2 negative loss (higher is better)\")\nplt.title(\"Convergence curve, averaged over targets\")\nplt.tight_layout()\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Compare to ``KernelRidgeCV``\nCompare to a baseline ``KernelRidgeCV`` model with all the concatenated\nfeatures. Comparison is performed using the prediction scores on the test\nset.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Fit the baseline model ``KernelRidgeCV``\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "baseline = KernelRidgeCV(kernel=\"linear\", alphas=alphas)\nbaseline.fit(X_train, Y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Compute scores of both models\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "scores = pipe.score(X_test, Y_test)\nscores = backend.to_numpy(scores)\n\nscores_baseline = baseline.score(X_test, Y_test)\nscores_baseline = backend.to_numpy(scores_baseline)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Plot histograms\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "bins = np.linspace(0, max(scores_baseline.max(), scores.max()), 50)\nplt.hist(scores_baseline, bins, alpha=0.7, label=\"KernelRidgeCV\")\nplt.hist(scores, bins, alpha=0.7, label=\"MultipleKernelRidgeCV\")\nplt.xlabel(r\"$R^2$ generalization score\")\nplt.title(\"Histogram over targets\")\nplt.legend()\nplt.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}